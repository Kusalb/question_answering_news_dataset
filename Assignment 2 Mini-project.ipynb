{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "## A. Tasks as specified for your team structure\n",
    "\n",
    "**One headings for each task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c729de",
   "metadata": {},
   "source": [
    "#### 1. Load date and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de57e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet   \n",
    "import pandas as pd\n",
    "import spacy\n",
    "import stanza\n",
    "import neuralcoref\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from torch.nn.functional import softmax\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "663f5a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/homes/Adam/NLP/ASM2/news_dataset.csv\"\n",
    "\n",
    "# 使用 with 语句确保文件正确关闭\n",
    "with open(file_path, 'rb') as file:\n",
    "    rawdata = file.read()\n",
    "\n",
    "result = chardet.detect(rawdata)\n",
    "encoding = result['encoding']\n",
    "\n",
    "# 在尝试读取之前打印编码以确认其正确性\n",
    "print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "# 检查编码是否被正确检测到，然后尝试读取文件\n",
    "if encoding:\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "else:\n",
    "    print(\"Failed to detect encoding. Consider specifying encoding manually.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6355c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>18456</td>\n",
       "      <td>Victor Mather</td>\n",
       "      <td>13/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>At least six members of the Super   New Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>18308</td>\n",
       "      <td>Ken Belson</td>\n",
       "      <td>8/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>sports</td>\n",
       "      <td>HOUSTON  ?   There was the game on the field, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>17636</td>\n",
       "      <td>Ron Lieber</td>\n",
       "      <td>14/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>When Wells Fargo announced its quarterly earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>17938</td>\n",
       "      <td>Dale Russakoff</td>\n",
       "      <td>29/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>When Indira Islas was in third grade at Centen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>18070</td>\n",
       "      <td>Laurie Goodstein</td>\n",
       "      <td>30/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>crime</td>\n",
       "      <td>Over the past decade, Christians in the United...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            author        date  year month     topic  \\\n",
       "993  18456     Victor Mather  13/02/2017  2017     2  politics   \n",
       "859  18308        Ken Belson   8/02/2017  2017     2    sports   \n",
       "298  17636        Ron Lieber  14/01/2017  2017     1  business   \n",
       "553  17938    Dale Russakoff  29/01/2017  2017     1  politics   \n",
       "672  18070  Laurie Goodstein  30/01/2017  2017     1     crime   \n",
       "\n",
       "                                               article  \n",
       "993  At least six members of the Super   New Englan...  \n",
       "859  HOUSTON  ?   There was the game on the field, ...  \n",
       "298  When Wells Fargo announced its quarterly earni...  \n",
       "553  When Indira Islas was in third grade at Centen...  \n",
       "672  Over the past decade, Christians in the United...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(n=100, random_state=np.random.seed(0))\n",
    "sample_df.head()\n",
    "# 随机抽取200个样本，加快训练速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12b8acbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# 假设以下是之前定义的预处理和实体提取函数的占位符\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and stem the words\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# 加载spaCy模型\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def extract_entities(text):\n",
    "    # 使用spaCy处理文本\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 提取实体\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "975810a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 清洗文本列\n",
    "sample_df['cleaned_article'] = sample_df['article'].apply(clean_text)\n",
    "\n",
    "# 向量化处理过的文本\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sample_df['cleaned_article'])\n",
    "# tfidf_matrix是处理过的数值数据，可以用于后续的NLP任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b151ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用函数提取每篇文章的实体\n",
    "sample_df['entities'] = sample_df['article'].apply(extract_entities)\n",
    "\n",
    "doc_id_to_index = {doc_id: index for index, doc_id in enumerate(sample_df.index)}\n",
    "#因为索引为随机的，所以需要一个字典来映射doc_id到索引\n",
    "\n",
    "inverted_index = defaultdict(set)\n",
    "for index, row in sample_df.iterrows():\n",
    "    for entity in row['entities']:\n",
    "        inverted_index[entity[0]].add(index)  # 假设entity[0]是实体的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47b01511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 10:08:23 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 26.9MB/s]                    \n",
      "2024-04-11 10:08:24 INFO: Downloaded file to /home/vscode/stanza_resources/resources.json\n",
      "2024-04-11 10:08:25 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| coref     | ontonotes_electra-large   |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-04-11 10:08:25 WARNING: GPU requested, but is not available!\n",
      "2024-04-11 10:08:25 INFO: Using device: cpu\n",
      "2024-04-11 10:08:25 INFO: Loading: tokenize\n",
      "2024-04-11 10:08:25 INFO: Loading: mwt\n",
      "2024-04-11 10:08:25 INFO: Loading: pos\n",
      "2024-04-11 10:08:25 INFO: Loading: lemma\n",
      "2024-04-11 10:08:25 INFO: Loading: coref\n",
      "2024-04-11 10:08:27 INFO: Loading: depparse\n",
      "2024-04-11 10:08:27 INFO: Loading: ner\n",
      "2024-04-11 10:08:28 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text: When Indira Islas was in third grade at Centennial Arts Academy, a public elementary school in Gainesville, Ga. she decided it was time to get serious. It was 2006, and she was in the lowest reading group in her class. She had been in that group since arriving two years earlier, speaking no English, in Gainesville, a city of 38, 000 just northeast of Atlanta?s booming outer suburbs. But being at the bottom went against everything she believed about herself. ?I wanted to be with the smart kids,? she recalls. Starting the year before, in second grade, she read every volume of the ?Magic Tree House? books in her   library, a series about two ordinary siblings who climb into their backyard treehouse and   to Pompeii, the Wild West, the ice age, feudal Japan and beyond. ?I absolutely loved them,? she says. ?It was like going on adventures all over the world. ? It was also the opposite of her own life. Indira left Mexico for the United States at age 6 with her parents and two younger sisters. Her mother cleaned houses when she wasn?t caring for the children  ?   there would eventually be seven of them  ?   and her father worked in construction, and there was no money for   lessons or soccer clubs, let alone traveling. ?I?d hear about trips and experiences of my white friends, and I remember thinking: I?ll never go to the beach or Disney World for spring break,? Indira says. Her parents told her that education was all that mattered, and she had to spend all her free time inside, reading and writing. ?I tell my children this country is a blessing to all the people living here,? her mother told me. ?If you have the opportunity to be good, it?s very important to take it. ? Indira took this advice to heart. By the time she was in fifth grade, her reading skills had improved so much that she tested into the top reading group. By middle school, she consistently got A?s, which qualified her for a celebratory school trip every time report cards came out. ?They rewarded us by taking us skating or bowling,? she says. ?I felt like I was so smart, just getting the chance to go out for the whole school day with friends. That?s when I said: ?I can make it. ??u2009? Indira began to throw herself into everything. At recess, she played soccer and basketball, competing so fiercely that everyone took notice. Boys usually picked other boys for their teams, and white kids tended to favor other white kids. But everyone started picking Indira. In middle school, she was on the track team, running   races. Her coach was stunned by her determination. In meets, even when she won her event, she scolded herself unless she broke her previous record. After practices ended, she would keep running. ?I wanted to think,? she says. ?I?d stay after practice and run and run and run. ? Indira remembers understanding vaguely that it wasn?t just poverty that set her and her family apart. Her parents had been doctors in Mexico. She admired pictures in their dresser drawer of the two of them in their 20s standing together, tall and proud in their white coats  ?   before they all fled the violence of drug gangs who were then taking over their home state, Guerrero. When she asked her parents why they were no longer doctors, they explained it was because they were not American citizens. It didn?t make sense to Indira. Why would her father have shed that beautiful crisp white coat for the fraying pants and shirts he now wore? Soon after Indira turned 13, in 2011, she was riding home from track practice with her mother when another car sideswiped the family?s Ford Expedition. The other driver, who was at fault, insisted on calling the police, according to Indira and a lawyer who assisted the family. Indira pleaded not to involve the police, explaining that her mother did not have a driver?s license because she was not an American citizen. (In Georgia and most other states, undocumented immigrants cannot obtain driver?s licenses.) But the driver said she needed a police report to get insurance to cover the damage to her car. A police officer arrived and asked for Indira?s mother?s license. When she said she did not have one  ?   a state crime  ?   she was told to get out of the car. Indira got out, too. She remembers two of her younger siblings sleeping in the back, one in a booster seat, one in a car seat. Two elders from the church they attended arrived to ask for mercy. She has seven children, they told the officer. He responded that he was simply enforcing the law. Indira?s mother turned to her and began to cry. ?Indira, I don?t know what is going to happen,? she said. ?They?re going to take me. ? Indira remembers remaining strangely calm. ?When she was being handcuffed, I said: ?Mom, everything is going to be O. K.??u2009? Indira?s mother was held in Gainesville?s Hall County jail for three days, but that wasn?t the most frightening part for the family. Hall is one of four counties in Georgia that have a formal agreement to report arrests of undocumented immigrants to the Department of Homeland Security, which means that infractions as minor as a   bulb above a license plate can spiral into deportation proceedings. Indira?s mother says that her charge of driving without a license ultimately led to a referral to immigration court and a deportation order instructing her to leave the country within 30 days. She stayed, slipping into the shadows. Every day since, Indira says, she and her siblings have feared that their mother would be deported. It would take only one more traffic stop. ?That woke me up,? Indira says. ?Until then, I thought the world was happy. ? In fact, she now realized, it was only American citizens who seemed truly happy. ?It must feel pretty good, I guess, to not have to worry about whether your family could be taken away any day. ? Indira has wanted to be a doctor for almost as long as she can remember. When she was 10, her family was shopping for groceries at Sam?s Club, and she spotted a large book about human anatomy. She became so excited about it that her parents bought it for her birthday, even though it was well above her reading level  ?   and their price range. She began working her way through it, mesmerized, and when she got stuck, her mother would explain whatever had stumped her. She was determined to go to college and medical school and fulfill her parents? interrupted dream. In her junior year, Indira began researching college options. She would be a strong applicant. She was consistently at or near the top of her class she was on the   track and soccer teams she volunteered over 1, 000 hours a year at the local hospital, a record in the history of the   program and she led her school?s chapter of the Hispanic Organization Promoting Education (HOPE) which encouraged Latino students  ?   who made up just over half the district?s population  ?   to stay in school and graduate. She was distressed to discover that Georgia barred undocumented immigrants from attending its top public universities and charged them    tuition at all others  ?   triple the rate for citizen residents. She then turned to researching financial aid and learned that Congress barred her from accessing federal Pell grants, loans, scholarships and   jobs  ?   the most common forms of assistance for   students. At first, she greeted this as just another set of obstacles to surmount, but as time went on, she began to despair. She would retreat to the classroom of her science teacher, Teresa Leach, who had become her mentor, in need of encouragement. ?There were a couple of times when I just cried to her because I was tired,? she said. ?I questioned myself if it was all worth the effort. ? All the while, Indira told me, she held onto her religious conviction that God had a plan, and that she must respect it. At a college fair attended by representatives of numerous Georgia colleges, she asked admissions officers what kind of help was available for undocumented students. No one had any to offer her. She switched her focus to private colleges and was admitted to Atlanta?s Agnes Scott, which she says awarded her $20, 000 annually in financial aid, less than half of what she needed. She researched   private scholarships and found two for undocumented students, but she was selected for neither. She was awarded seven small scholarships, which totaled $10, 000, enough to go to a nearby public commuter college for only one semester at the    tuition rate. Last May, Indira attended her graduation ceremony at Gainesville High School, but she had nowhere to go next. In every picture from that day, she wears a wide smile, but she was in pain inside, particularly when she caught a glimpse of her mother in the crowd, looking distraught. Unable to bring herself to celebrate with friends, she went home to be with her family. Days later, a friend told her about a philanthropic organization called TheDream. US, which was offering undocumented students full   scholarships to Delaware State University or Eastern Connecticut State University. The application was demanding, and only 76 students would be chosen. She poured herself into the essays, spending hours composing them alongside an English teacher, Cindy Lloyd. She applied to Delaware State, a historically black college in Dover, five hours closer to home than Eastern Connecticut. In late June, she received an email from TheDream. US. ?I saw ?Congratulations,??u2009? she remembers, ?and I read no more. ? In late August, Indira made the   drive with her parents from Gainesville to Delaware State in unusual silence. She was thinking hard about each of her six younger siblings, wondering how they would fare without her. Over breakfast at a Cracker Barrel in South Carolina, when her mother pressed her about how she was feeling, she talked only of her concerns about not being at home to help everyone. When she arrived on campus  ?   a flat expanse of grassy courtyards and buildings amid strip malls, auto dealers and chain restaurants just beyond Dover?s historic capital area  ?   she found 33 other ?opportunity scholars,? just as worried and hopeful as she was. All of them were assigned to a dorm about a quarter of a mile from the D. S. U. campus, a former Sheraton hotel acquired a few years earlier by the university as part of an expansion. They bonded instantly, traveling as a posse from classes to the library to the cafeteria, often ending up together late at night in the dorm lobby or in a lounge that had been a large hotel suite on the second floor. In their first month on campus, the opportunity scholars were invited to a welcoming ceremony in the school?s Martin Luther King Jr. Student Center with Gov. Jack Markell the Democratic senator Tom Carper Donald Graham, a founder of TheDream. US and D. S. U. ?s president, Harry Williams. ?This is not just an opportunity for you it is an opportunity for the state of Delaware,? Markell told them. ?It is sad to see your own home state reject such talent and potential. ? He pronounced himself ?thrilled that you?re here. ? It was the first time many of the students could recall being welcomed anywhere. ?We felt rejection our whole lives from our own states,? Indira said. ?We were here only three weeks, and we already met the governor and the senator. It felt like saying ?Haha!? to Georgia. ? Of the 34 opportunity scholars enrolled at D. S. U. 28 are from Mexico and one each is from Ecuador, El Salvador, Peru, Gabon, Gambia and Trinidad and Tobago. Their families are a composite portrait of the economic forces that have drawn undocumented immigrants to the nation?s small towns and metropolitan heartland. Their parents work in poultry plants, on factory lines, in warehouses, on construction sites, in restaurants they clean and paint houses and schools, tend gardens. ?They make everything look perfect for the tourists,? Yulma Lopez, who left Mexico at age 3, said of her parents? work for a landscaping company in Charleston, S. C. Almost all their parents work illegally, but many pay income taxes, having obtained federal   numbers. And some, including Indira?s father, have secured temporary federal permission to work and drive lawfully. While most of the students are 18 or 19, typical for college freshmen, some have worked for years in hopes of one day saving enough for college. Olivia Bekale, who is 27 and grew up in Baton Rouge, arrived in Louisiana from Gabon as a child. She graduated from high school in 2008 with a 3. 9 G. P. A. from the Louisiana School for Math, Science and the Arts, a prestigious   boarding school for top achievers. Unable to afford college, she cycled from one   position to the next  ?   server at the Melting Pot, a fondue restaurant retail sales consultant for Sprint   agent for Marriott pharmacy tech for Walgreens. Olivia, who had wanted to be a doctor since an aunt died of AIDS when she was 5, had been out of high school for eight years when she learned of the opportunity scholarship she applied immediately. All but one of the students were enrolled in the Deferred Action for Childhood Arrivals program, also known as DACA. Created in 2012 by an   executive action, DACA allowed teenagers and young adults who came to the United States illegally as children with their parents to register with the government and in turn receive a   renewable protection against deportation, along with work permits and Social Security numbers. Most of the students, like Indira, signed up at age 15, as soon as they were eligible. With DACA, Indira, who is now 18, was able to get a driver?s license and a job at a Publix supermarket when she was in high school, working 20 hours a week as a cashier and bagger. Being able to work and drive legally, free of the fears her mother faced, and fitting in with her classmates, Indira says, was ?living the American dream. ? With her income from Publix, she even was able to get braces for her teeth. The starting point for all of their dreams was education, and the quest for it has been central to the experience of undocumented young people since long before Indira and her classmates were born. In the late 1970s, when undocumented immigrants had yet to move in large numbers beyond border states, Texas passed a law authorizing local school districts to ban them from public schools or charge them tuition. In a landmark decision in Plyler v. Doe in 1982, a narrowly divided Supreme Court struck down the law, finding that undocumented children had a constitutional right to free    public education. The opinion blamed a dysfunctional immigration system for creating the crisis by failing to keep out undocumented immigrants or provide them a path to citizenship. ?Already disadvantaged as a result of poverty, lack of   ability and undeniable racial prejudices, these children, without an education, will become permanently locked into the lowest socioeconomic class,? Justice William Brennan wrote for the majority, quoting the   opinion. The case also introduced the argument that undocumented children were legally blameless, unlike their parents: ?The classification at issue deprives a group of children of the opportunity for education afforded all other children simply because they have been assigned a legal status due to a violation of law by their parents,? Justice Lewis Powell wrote in a concurring opinion. Undocumented children poured into the nation?s schools over the next generation, and as they reached college age, they coalesced into a movement, advocating access to higher education as well as full citizenship. In 2001, they began calling themselves Dreamers, now an estimated 2. 1 million young immigrants who have grown up as Americans in almost every way except for their passports. The name came from the Dream Act (Development, Relief and Education for Alien Minors) introduced in Congress in 2001 by Senator Richard Durbin, a Democrat from Illinois, and Senator Orrin Hatch, a Republican from Utah, and for which activists fought for over a decade. The measure, which would have put undocumented children on a path to citizenship, never passed, but the vast network of Dreamers became a compelling political force. In 2001, hundreds of them turned out to testify in Texas in favor of legislation to allow undocumented residents to pay   college tuition if they graduated from Texas high schools and lived in the state for three years. ?Something magical happened when those kids told their stories,? says the former Texas state representative Rick Noriega, a Democrat who sponsored the bill. ?It was a humanizing of a very real issue dealing with children?s dreams and hopes. Every heart on that committee was touched, Republicans and Democrats. ? The legislation passed both houses almost unanimously and was signed by Rick Perry, then governor of Texas and now President Donald Trump?s pick for energy secretary. Texas became the first state, followed quickly by California, to allow Dreamers to pay   tuition. Today, 21 states charge Dreamers the same tuition as legal residents, including six carried by Trump  ?   Florida, Kansas, Nebraska, Oklahoma, Utah and Texas. In many of those states, however, the   issue has turned politically treacherous. In Texas, efforts to repeal the tuition law come closer to passing every year, and Noriega says there is no chance the original measure would pass today. The leading national opponents of   tuition for Dreamers include the Republican senator Jeff Sessions, Trump?s choice for attorney general, and the secretary of state of Kansas, Kris Kobach, a Republican who was a leader of Trump?s transition team on immigration. Each argues that students who are in the United States illegally should not get a public benefit in any state that is denied to a citizen from another state. In other words, if Dreamers pay   tuition in Texas, citizen students next door in Arkansas and Oklahoma  ?   or Massachusetts, for that matter  ?   should have the same right. ?How much sense does that make, to have people here illegally, and they have more benefits than those who are here legally?? Sessions asked in a Senate floor statement. Kobach used the same argument to bring   lawsuits against   tuition for Dreamers in Kansas and California. Judges found no legal basis for the claims and dismissed the cases. The larger debate over how to treat an estimated 11 million immigrants who came here illegally has been at a stalemate for decades, with advocates seeking a ?path to citizenship? for   families who have been in the country for years and opponents denouncing ?amnesty? for people who broke the law to enter the country. Amid hardening resistance in Congress to immigration reform, Dreamers brought pressure on Obama  ?   including   and hunger strikes at his 2012 campaign offices  ?   to use his executive power to create DACA. The program, announced on June 15, 2012, the 30th anniversary of the Supreme Court?s Plyler decision, proved transformative for Dreamers. They have entered college, taken    jobs, received driver?s licenses, bought cars. They now fly on planes, passing effortlessly through airport security. They still lack legal immigration status, but no longer are they exactly undocumented. ?DACAmented,? many have called themselves. Even in states where they pay   tuition, Dreamers still struggle to afford college because they are disproportionately   and have no access to federal financial aid. Fewer than 10 percent of Dreamers who graduate from high school enroll in college. At a time when college graduates earn 70 percent more than those without degrees, these numbers conjure the 1982 warning by the Supreme Court that undocumented children could become a permanent underclass. In response, a handful of philanthropies have adopted the cause of sending students with DACA status to college. The biggest of these, TheDream. US, has raised $90 million to eventually finance 4, 000 students at public colleges, with significant contributions from Donald Graham, former publisher and chief executive of The Washington Post, and his family Mark Zuckerberg and Priscilla Chan Bill and Melinda Gates the   executive William Ackman and Michael Bloomberg, among others. (I was a reporter at The Washington Post from 1980 to 2008.) In 2014, TheDream. US began offering Dreamers full scholarships in states that charge them   tuition. Last year, in partnership with Delaware and Connecticut, the organization created the   program for students from the other 29 states, financed by $41 million in philanthropy from Graham and his family and two anonymous donors. The governors of Delaware and Connecticut agreed to charge roughly   tuition rates for the 34 scholars at Delaware State and the 42 at Eastern Connecticut State  ?   a total of $80, 000 per student for tuition, room and board for four years. In an effort to   political opposition, Graham says, the philanthropy works only with schools, like Delaware State and Eastern Connecticut State, that have excess capacity, so that undocumented students are not displacing citizens. And private donors pay all expenses, so that no state dollars are spent. Still, when The Delaware State News ran an article in September about the D. S. U. opportunity scholars, the online comments complained that undocumented immigrants, not citizens, were benefiting. ?Trump isn?t perfect, but I will vote for him because he puts Americans FIRST,? wrote a reader named John Huff of Magnolia, Del. ?There are plenty of kids who are citizens who have the same dream and should come first. ? And as news of the scholarship spread on the Delaware campus this fall, a number of   students told Dreamers that they resented that their own families had to go into debt for a portion of their education costs while the DACA students got full scholarships. By then, Trump had mobilized   anger in large swaths of the country, having kicked off his campaign criticizing Mexican immigrants  ?   ?They?re bringing drugs. They?re bringing crime. They?re rapists?  ?   and vowing to build a wall on the border to keep them out. In stump speeches, he promised to deport all 11 million undocumented immigrants and, in his first 100 days in office, to terminate DACA, labeling it ?illegal amnesty. ? Both vows became instant applause lines. Indira declared her major in biological sciences at the beginning of the semester and started a demanding   curriculum with six classes, including biology and chemistry, both requiring labs. Her parents had insisted she not take a job, in order to devote herself to education, freeing up four hours a night that she had spent working in high school. With that extra time, she found the academic challenges manageable. Much harder was living apart from her   family for the first time in her life. Her mother texted her daily. ?Good morning, hija,? she wrote one recent morning, using the Spanish word for daughter. ?May God bless you today in school. Please be kind to everyone. ? That night, over FaceTime, Indira talked with two of her younger sisters, who like her were born in Mexico and are undocumented. One, a junior in high school, is already on a quest for college scholarships. She and Indira came up with potential essay ideas and discussed her r?sum?. Then Indira helped the other, a freshman who is the smartest of all the family?s children, Indira says, with physics homework. On weekends, she FaceTimes with her four youngest siblings  ?   a sixth grader, a fourth grader, a third grader and a first grader  ?   all of whom were born in Georgia and are citizens. Separation from family, from home, even from Mexican food made most of the opportunity scholars profoundly lonely. Estephany Martinez, a petite   major with long black hair, couldn?t stop thinking about her sisters in the first weeks. ?Whenever we came home from school, all four sisters would sit in the living room and do our homework and talk and watch TV,? she recalled wistfully of her life in Winder, Ga. In Delaware, ?I didn?t have anybody that cared for me. I didn?t have anyone to come home to. ? In early September, she summoned all the scholars to a gathering in the dorm?s   lounge. ?All right, you guys, we?re going to be here for each other,? she said. ?That part of our lives  ?   being undocumented  ?   is critical to who we are. We have to share our stories. ? Everyone crowded in, sitting on the sofa, spilling onto the floor, sitting shoulder to shoulder on counters that once were part of a kitchenette, sprawling into one another?s space. Carlos Gonzales of Manteo, N. C. a lanky and cheerful marketing major whose mother is a restaurant cook, broke down crying when he recalled the violence that drove his family from Mexico City. He, his mother and his younger sister moved to North Carolina when he was 7. It was his mother who encouraged him, beginning in elementary school, to reach for college. ?I don?t want you to live the life we?re living now,? she told him. In high school, he was an honor student and varsity wrestler and runner, working nights and weekends at McDonald?s in his Outer Banks town. When he received the email telling him he was an opportunity scholar, he said: ?I hugged my mom and cried for two hours. The only reason I stopped was I had to go to work. ? Indira told the harrowing story that led to her own family?s departure from Mexico. In 2004, when she was 6, three masked gunmen broke into their home, which housed her parents? clinic, and robbed them of everything  ?   money, jewelry, a new computer, a television, cameras and medications. They filed a report with the police, they said, who didn?t investigate, in deference to cartels then taking over Guerrero, now the most violent state in Mexico. An uncle of her father?s already had been killed. In subsequent years, a cousin of her mother?s, a veterinarian, was kidnapped and never found. Two nephews disappeared. Her mother?s sister has been kidnapped twice  ?   most recently this past November  ?   and returned only after her family paid steep ransoms. Weeks after the robbery, Indira?s family of five arrived in the United States on a tourist visa that her father procured a month earlier in hopes of taking everyone to Disney World. Instead, they went to Gainesville, where her father?s brother worked in construction  ?   one of thousands of Mexican workers who flocked to the north Georgia community in the last 25 years, swelling the Hispanic population to more than 40 percent in 2013 from 8 percent in 1990. Indira said her parents are certain they would have been killed had they stayed. They decided to forfeit their careers for their family?s safety. ?I no longer saw my future, but I saw my children?s future,? her father said to me. Antonio Patino, a   major who is a lifeguard and plays bass and guitar in his spare time, told the group about riding with his family in their car in 2015 in Lawrenceville, Ga. when a police officer pulled them over, though none of them understood why. His father, who is undocumented and processes returns for a local manufacturer, was driving but did not have a license. Antonio and his mother, younger sister and brother all watched in terror as his father was handcuffed, placed in a police cruiser and driven off to jail. As it turned out, he was released the next day after paying a fine of more than $800 and was not referred to immigration court for further proceedings, but the incident shook Antonio?s sense of belonging in America. ?I felt like I got slapped in the face just for living, trying to be a normal person in this beautiful country,? he said. ?It feels like a hole inside me. ? He said he now found himself gripped with fears for his parents? safety at random moments during his days at D. S. U. It is as if he has swapped roles with his mother and father. ?Like I?m now the parent and they?re the child, and I?m worried for them,? he told me. ?Not being there, all these   swarm into my mind. What if out of nowhere they get pulled over again?? Calling them and hearing their voices usually comforts him. But after one such call, he said: ?I went outside, and I had to cry a little. I was feeling like I couldn?t help them. ? A number of students shared the enormous sacrifices they had seen their parents make for them. Juan Chavez, 23, who grew up in Plymouth, Ind. and worked for five years after high school, told of his mother suffering a breakdown after her divorce from his father. He saw it as a response to the crushing instability of their lives, moving from one home to another in search of shelter. ?She?s the strongest person I?ll ever know,? he said. ?She?s my role model. My father figure as well as my mother. ? He continued: ?I felt so helpless to make things better. I decided almost right then I?ll go to college and medical school if it takes me the rest of my life. ? He is now a psychology and   major, intending to become a psychiatrist. On and on the students went until almost 3 a. m. the common threads in their stories drawing them closer. It was the first time most of them had talked openly about being undocumented, but instead of feeling exposed, they felt safer. Until then, Antonio had gone out of his way to avoid conversations with   at D. S. U. about his scholarship, not wanting to have to explain that he got it because he was undocumented. The next day, though, he fell into conversation with a student who asked him how he happened to come all the way from Georgia to D. S. U. and he said without hesitation: ?I got a scholarship. ? ?What for?? ?I?m undocumented,? Antonio said, surprised at how comfortable this felt. ?O. K. man, that?s cool,? the student said. After their long night talking, the scholars also better understood what had propelled them all for as long as they could remember. Throughout high school, the opportunity scholars watched undocumented friends and siblings give up and drop out, shamed and beaten down by public scorn over illegal immigration and the   options awaiting even those who excelled in high school. But they kept on striving, steeled to the insults, positioning themselves for a breakthrough they couldn?t yet see. Now this all made sense. ?This pain  ?   it pushes us,? Estephany said. ?It?s motivation. It has made me who I am. It makes me go through every day. ? ?Now we know what drives us,? Indira said. One morning in   at 9:50 a. m. 10 minutes before Indira?s   class was scheduled to start, she and two other opportunity scholars were already ensconced in the three center   seats, notebooks, pens and textbooks at the ready. Indira was wearing a Harvard sweatshirt that a classmate bought for her when their   A. P.  class visited Boston. (Indira couldn?t afford to go.) ?I?m going to get there one day,? she said with a confident smile. Most of the other students didn?t arrive until class was about to begin  ?   or later  ?   and there was little competition for the front rows. A similar scene unfolded that morning in the ultramodern science center, in   class, where Antonio and Jose Reyes Rios, another   major, sat front and center with an   classmate named Hanqaamo Lintisio, who is from Maryland and has a track scholarship. The three had formed a study group and tutored one another so effectively that they all scored above 100 on the midterm. (They nailed the bonus question.) Theirs were the only A?s in the class. The Dreamers gather daily at a long Formica table in a D. S. U. cafeteria for food and conversation. At lunch, Carla Moreno propped her English composition textbook, ?Patterns for College Writing,? against a napkin holder, securing it with an apple. She paged through a chapter while eating her salad and chili dog. ?It?s just a quiz,? she said, ?but I want to keep my A. ? ?I deal with a lot of students, and I feel like the Dreamers are at a different level,? says Kevin Noriega, the adviser for their scholarships. ?They?re saying, ?I?ve got to make this happen because it?s my only option. ??u2009? Of the 488 scholars funded by TheDream. US who began college in 2014, 94 percent remain enrolled after their sophomore year research shows that only 66 percent of   college students nationally return after one year. ?This is a   population with retention rates like Harvard?s,? Donald Graham says. Because beneficiaries of TheDream. US have full rides, they avoid a common problem faced by other disadvantaged students: running short of money for costs not covered by Pell grants or other forms of aid. One night in October before a biology exam, Indira went to the D. S. U. athletic center for a workout to relieve stress. She was armed with a stack of homemade flash cards and her iPhone, on which she had downloaded discussions of test topics from various websites. While pounding ou\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse,ner,coref', use_gpu=True)\n",
    "\n",
    "def coref_resolve(text, nlp):\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        representative_mentions = []\n",
    "        for sentence in doc.sentences:\n",
    "            for token in sentence.tokens:\n",
    "                for word in token.words:\n",
    "                    if hasattr(word, 'coref_chains'):\n",
    "                        for chain in word.coref_chains:\n",
    "                            if chain.is_representative:\n",
    "                                representative_mentions.append(word.text)\n",
    "                                break\n",
    "        return representative_mentions\n",
    "    except IndexError:\n",
    "        print(\"Error processing text:\", text)\n",
    "        return []\n",
    "    \n",
    "\n",
    "sample_df['coref_chains'] = sample_df['article'].apply(lambda x: coref_resolve(x, nlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2cbd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_entities_to_corefs(entities, coref_chains):\n",
    "    entity_coref_map = {}\n",
    "    for entity in entities:\n",
    "        entity_text = entity[0]  # Assuming entities are tuples of (text, type)\n",
    "        entity_coref_map[entity_text] = []\n",
    "        for coref in coref_chains:\n",
    "            if entity_text in coref:\n",
    "                entity_coref_map[entity_text].append(coref)\n",
    "    return entity_coref_map\n",
    "\n",
    "# Apply this function row-wise, assuming 'coref_chains' and 'entities' are available for each row\n",
    "sample_df['entity_coref_map'] = sample_df.apply(lambda row: map_entities_to_corefs(row['entities'], row['coref_chains']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7efe179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query_text):\n",
    "    # 对查询进行预处理和实体识别\n",
    "    cleaned_query = clean_text(query_text)\n",
    "    query_vector = vectorizer.transform([cleaned_query])\n",
    "    query_entities = extract_entities(query_text)\n",
    "    \n",
    "    # 基于实体和共指信息查找文档\n",
    "    docs_based_on_content = set()\n",
    "    for entity_text, _ in query_entities:\n",
    "        # 使用倒排索引直接根据实体查找文档\n",
    "        docs_based_on_content.update(inverted_index.get(entity_text, []))\n",
    "        \n",
    "        # 使用共指信息查找相关文档\n",
    "        for doc_id in sample_df.index:\n",
    "            coref_map = sample_df.at[doc_id, 'entity_coref_map']\n",
    "            for coref_entity, mentions in coref_map.items():\n",
    "                if entity_text == coref_entity or entity_text in mentions:\n",
    "                    docs_based_on_content.add(doc_id)\n",
    "                    break  # 如果找到匹配，就跳出循环\n",
    "\n",
    "    # 直接使用找到的文档进行评分和排序\n",
    "    if docs_based_on_content:\n",
    "        docs_indices = [doc_id_to_index[doc_id] for doc_id in docs_based_on_content if doc_id in doc_id_to_index]\n",
    "        docs_tfidf = tfidf_matrix[docs_indices]\n",
    "        cos_similarities = cosine_similarity(query_vector, docs_tfidf).flatten()\n",
    "        \n",
    "        scored_docs = sorted(zip(docs_based_on_content, cos_similarities), key=lambda x: x[1], reverse=True)\n",
    "        ranked_docs = [doc[0] for doc in scored_docs]\n",
    "        \n",
    "        return ranked_docs\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8198e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found documents: [494]\n"
     ]
    }
   ],
   "source": [
    "query_text = input(\"Enter your query text: \")\n",
    "\n",
    "\n",
    "ranked_docs = search_documents(query_text)\n",
    "if ranked_docs:\n",
    "    print(f\"Found documents: {ranked_docs}\")\n",
    "else:\n",
    "    print(\"No documents found or query format incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "888048da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 定义全局变量\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    # 使用全局变量bert_tokenizer和bert_model处理文本\n",
    "    inputs = bert_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def find_top_n_relevant_contents(question, article_content, top_n=5, window_size=5):\n",
    "    # 使用spaCy进行句子分割\n",
    "    doc = nlp(article_content)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # 获取句子文本并去除首尾空白\n",
    "\n",
    "    # 其余的逻辑与之前相同\n",
    "    paragraph_embeddings = []\n",
    "    for i in range(len(sentences) - window_size + 1):\n",
    "        window_sentences = ' '.join(sentences[i:i+window_size])\n",
    "        window_embedding = get_bert_embeddings([window_sentences])[0]  # 假设get_bert_embeddings返回numpy数组\n",
    "        paragraph_embeddings.append(window_embedding)\n",
    "\n",
    "    paragraph_embeddings = np.array(paragraph_embeddings)\n",
    "    question_embedding = get_bert_embeddings([question])[0]\n",
    "\n",
    "    # 计算相似度并找到最相关的窗口\n",
    "    similarities = cosine_similarity([question_embedding], paragraph_embeddings).flatten()\n",
    "    top_n_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    top_n_contents = [(' '.join(sentences[i:i+window_size]), similarities[i]) for i in top_n_indices]\n",
    "\n",
    "    return top_n_contents\n",
    "\n",
    "\n",
    "def encode_question_and_context(question, context):\n",
    "    # 使用全局变量qa_tokenizer对问题和上下文进行编码\n",
    "    return qa_tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "# def find_answer(question, context):\n",
    "#     # 使用全局变量qa_tokenizer和qa_model找到问题的答案\n",
    "#     inputs = encode_question_and_context(question, context)\n",
    "#     input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "#     outputs = qa_model(**inputs)\n",
    "#     answer_start_scores = outputs.start_logits\n",
    "#     answer_end_scores = outputs.end_logits\n",
    "\n",
    "#     answer_start = torch.argmax(answer_start_scores)\n",
    "#     answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "#     answer = qa_tokenizer.convert_tokens_to_string(qa_tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    \n",
    "#     return answer\n",
    "\n",
    "\n",
    "def find_answer(question, context, top_k=3):\n",
    "    inputs = encode_question_and_context(question, context)\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    outputs = qa_model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    # 计算开始和结束分数的softmax分布\n",
    "    start_probs = softmax(answer_start_scores, dim=-1)\n",
    "    end_probs = softmax(answer_end_scores, dim=-1)\n",
    "\n",
    "    # 提取排名前top_k的开始和结束位置\n",
    "    start_topk = torch.topk(start_probs, top_k)\n",
    "    end_topk = torch.topk(end_probs, top_k)\n",
    "\n",
    "    top_answers = []\n",
    "    for start_index, start_score in zip(start_topk.indices[0], start_topk.values[0]):\n",
    "        for end_index, end_score in zip(end_topk.indices[0], end_topk.values[0]):\n",
    "            # 确保结束位置在开始位置之后\n",
    "            if end_index >= start_index:\n",
    "                answer = qa_tokenizer.convert_tokens_to_string(qa_tokenizer.convert_ids_to_tokens(input_ids[start_index:end_index + 1]))\n",
    "                score = (start_score.item() + end_score.item()) / 2  # 简单地取平均分数作为置信度\n",
    "                top_answers.append((answer, score))\n",
    "                break  # 只添加每个开始位置的最佳结束位置\n",
    "\n",
    "    # 根据置信度分数降序排列答案\n",
    "    top_answers = sorted(top_answers, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return top_answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e1f9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEIJING  ? It seemed that China?s censors had finally muzzled Yang Jisheng, the famed chronicler of the Mao era. Last year, he had finished writing a widely anticipated history of the Cultural Revolution. But officials warned him against publishing it and barred him from traveling to the United States, he has said, and he stayed muted through the 50th anniversary of the start of that bloody upheaval. Now Mr. Yang has broken that silence with the publication of his history of the Cultural Revolution, ? In a sign of how Chinese politics has chilled, Mr. Yang has said little publicly about the book. ? Since the book was published, I?ve been told not to discuss it with foreign media,? he said in a brief telephone conversation. He would not say whether he had authorized ? The World Turned Upside Down? It seemed that China?s censors had finally muzzled Yang Jisheng, the famed chronicler of the Mao era. Last year, he had finished writing a widely anticipated history of the Cultural Revolution. But officials warned him against publishing it and barred him from traveling to the United States, he has said, and he stayed muted through the 50th anniversary of the start of that bloody upheaval. Now Mr. Yang has broken that silence with the publication of his history of the Cultural Revolution, ? The World Turned Upside Down,? Now Mr. Yang has broken that silence with the publication of his history of the Cultural Revolution, ? The World Turned Upside Down,? a sequel to ? Tombstone,? his landmark study of the famine spawned by Mao?s policies in the late 1950s. he said in a brief telephone conversation. He would not say whether he had authorized ? The World Turned Upside Down? to be published in Hong Kong. ? There?s quite a lot of pressure,?\n",
      "\n",
      "Answer from relevant content: [('[CLS]', 0.22907434403896332), ('[SEP]', 0.22906894236803055), ('[SEP]', 0.2290584146976471)]\n",
      "\n",
      "Answer from all content: [('1966', 0.9970089495182037), ('in 1966', 0.4985171376320068), ('mao started in 1966', 0.4984065386815928)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Who is the famed chronicler of the Mao era who finished writing a history of the Cultural Revolution?\n",
    "\n",
    "while True:\n",
    "    query_text = input(\"Enter your query text (or type 'exit' to exit): \")\n",
    "    if query_text.lower() == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # 假设ranked_docs是通过某种方式得到的文档ID列表\n",
    "    ranked_docs = search_documents(query_text)\n",
    "    if not ranked_docs:\n",
    "        print(\"No documents found or query format incorrect.\")\n",
    "        continue\n",
    "\n",
    "    # 这里需要定义如何根据doc_id获取到实际的文档内容，例如拼接所有相关文档的内容作为context\n",
    "    all_articles = ''\n",
    "    # 假设sample_df是包含文档的DataFrame，并且我们已经获取了相关的doc_ids\n",
    "    for doc_id in ranked_docs:\n",
    "        article = sample_df.loc[doc_id, 'article']  # 假设这样可以获取到文档内容\n",
    "        all_articles += article + ' '\n",
    "\n",
    "    \n",
    "    top_n_contents = find_top_n_relevant_contents(query_text, all_articles)\n",
    "    relevant_context = ' '.join([content for content, score in top_n_contents])\n",
    "    print(relevant_context + '\\n')\n",
    "\n",
    "    # 使用相关内容寻找答案\n",
    "    answer_from_relevant_content = find_answer(query_text, relevant_context)\n",
    "    print(f\"Answer from relevant content: {answer_from_relevant_content}\\n\")\n",
    "\n",
    "    # 直接在整个文档上寻找答案进行对比\n",
    "    answer_from_all_content = find_answer(query_text, all_articles)\n",
    "    print(f\"Answer from all content: {answer_from_all_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c7cd72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leap communist utopia mr yang chronicl tombston book publish chines hong kong 2008 yang jisheng historian editori global time ardent chines newspap said last year leav impress interest histori virtual later work display strong polit tendenc last year die famin 1958 caus great leap forward mao reckless attempt leap communist utopia mr yang chronicl tombston book publish chines hong kong 2008 yang jisheng historian editori global time ardent chines newspap said last year leav impress interest histori china mr guo ad mr yang extens access archiv new book wrote tombston instead drew hundr memoir histori studi mani publish hong kong avail onlin fewer revel previou book recent scholarship mr yang emphas much worst bloodsh came later cultur revolut mao brought back militari parti apparatu brutal enforc order fair say work emin journalist mr yang book mean first histori cultur revolut sever publish offici auspic mainland china earlier decad chines govern tri confront ordeal era recent year parti becom much wari allow research mani younger peopl sketchi idea happen mao start cultur revolut purg china saw threat puriti surviv revolut mr yang want reader rememb tragedi past whether great famin cultur revolut reflect make sens tragedi would repeat said mr guo translat consid task conscienti remember urgent face offici enforc histor amnesia china mr guo ad mr yang extens access archiv new book wrote tombston instead drew hundr memoir histori studi mani publish hong kong avail onlin fewer revel previou book recent scholarship cultur revolut sever publish offici auspic mainland china earlier decad chines govern tri confront ordeal era recent year parti becom much wari allow research mani younger peopl sketchi idea happen mao start cultur revolut purg china saw threat puriti surviv revolut mr yang want reader rememb tragedi past whether great famin cultur revolut reflect make sens tragedi would repeat said mr guo translat consid task conscienti remember urgent face offici enforc histor amnesia china mr guo ad mr yang extens access archiv new book wrote tombston instead drew hundr memoir histori studi mani publish hong kong avail onlin fewer revel previou book recent scholarship mr yang emphas much worst bloodsh came later cultur revolut mao brought back\n",
      "\n",
      "Answer from relevant cleaned_content: [('[CLS]', 0.3187607079744339), ('[SEP]', 0.3187500387430191), ('[SEP]', 0.3186635375022888)]\n",
      "\n",
      "Answer from all cleaned_content: [('[CLS]', 0.3032791018486023), ('[SEP]', 0.30326977372169495), ('[SEP]', 0.3032239079475403)]\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Who is the famed chronicler of the Mao era who finished writing a history of the Cultural Revolution?\n",
    "\n",
    "while True:\n",
    "    query_text = input(\"Enter your query text (or type 'exit' to exit): \")\n",
    "    if query_text.lower() == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # 假设ranked_docs是通过某种方式得到的文档ID列表\n",
    "    ranked_docs = search_documents(query_text)\n",
    "    if not ranked_docs:\n",
    "        print(\"No documents found or query format incorrect.\")\n",
    "        continue\n",
    "\n",
    "    # 这里需要定义如何根据doc_id获取到实际的文档内容，例如拼接所有相关文档的内容作为context\n",
    "    all_articles = ''\n",
    "    # 假设sample_df是包含文档的DataFrame，并且我们已经获取了相关的doc_ids\n",
    "    for doc_id in ranked_docs:\n",
    "        article = sample_df.loc[doc_id, 'cleaned_article']  # 假设这样可以获取到文档内容\n",
    "        all_articles += article + ' '\n",
    "\n",
    "    \n",
    "    top_n_contents = find_top_n_relevant_contents(query_text, all_articles)\n",
    "    relevant_context = ' '.join([content for content, score in top_n_contents])\n",
    "    print(relevant_context + '\\n')\n",
    "\n",
    "    # 使用相关内容寻找答案\n",
    "    answer_from_relevant_content = find_answer(query_text, relevant_context)\n",
    "    print(f\"Answer from relevant cleaned_content: {answer_from_relevant_content}\\n\")\n",
    "\n",
    "    # 直接在整个文档上寻找答案进行对比\n",
    "    answer_from_all_content = find_answer(query_text, all_articles)\n",
    "    print(f\"Answer from all cleaned_content: {answer_from_all_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbf1cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_answer_question(query_text, use_relevant_content=True):\n",
    "    # 假设ranked_docs是通过某种方式得到的文档ID列表\n",
    "    ranked_docs = search_documents(query_text)\n",
    "    if not ranked_docs:\n",
    "        return \"No documents found or query format incorrect.\"\n",
    "\n",
    "    # 获取所有相关文档的内容\n",
    "    all_articles = ''\n",
    "    for doc_id in ranked_docs:\n",
    "        # 假设可以通过doc_id获取到文档内容\n",
    "        article = sample_df.loc[doc_id, 'article']\n",
    "        all_articles += article + ' '\n",
    "\n",
    "    # 根据use_relevant_content变量决定使用哪种内容寻找答案\n",
    "    if use_relevant_content:\n",
    "        # 找到与问题最相关的内容片段\n",
    "        top_n_contents = find_top_n_relevant_contents(query_text, all_articles, top_n=3)\n",
    "        relevant_context = ' '.join([content[0] for content in top_n_contents])\n",
    "        context_to_use = relevant_context\n",
    "    else:\n",
    "        # 使用全部内容\n",
    "        context_to_use = all_articles\n",
    "\n",
    "    # 使用选择的内容寻找答案\n",
    "    answer = find_answer(query_text, context_to_use)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "02697316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(predicted_answers, truths):\n",
    "    f1_scores = []\n",
    "    for predicted in predicted_answers:  # 不需要解包\n",
    "        pred_tokens = predicted.split()\n",
    "        truth_tokens = set([answer for truth in truths for answer in truth.split()])\n",
    "        common = set(pred_tokens) & truth_tokens\n",
    "        if not common:\n",
    "            f1_scores.append(0)\n",
    "            continue\n",
    "        precision = len(common) / len(pred_tokens)\n",
    "        recall = len(common) / len(truth_tokens)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        f1_scores.append(f1)\n",
    "    return np.mean(f1_scores) if f1_scores else 0\n",
    "\n",
    "\n",
    "def compute_mrr(predicted_article_ids, truth_article_ids):\n",
    "    rank = 0\n",
    "    for i, predicted_id in enumerate(predicted_article_ids, start=1):\n",
    "        if predicted_id in truth_article_ids:\n",
    "            rank = 1 / i\n",
    "            break\n",
    "    return rank\n",
    "\n",
    "\n",
    "def compute_map(predicted_article_ids, truth_article_ids):\n",
    "    avg_precisions = []\n",
    "    for i, predicted_id in enumerate(predicted_article_ids, start=1):\n",
    "        if predicted_id in truth_article_ids:\n",
    "            relevant_count = sum(pred_id in truth_article_ids for pred_id in predicted_article_ids[:i])\n",
    "            precision_at_i = relevant_count / i\n",
    "            avg_precisions.append(precision_at_i)\n",
    "    return np.mean(avg_precisions) if avg_precisions else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lcs_length(x, y):\n",
    "    \"\"\"计算两个序列的最长公共子序列（LCS）的长度\"\"\"\n",
    "    if not x or not y:\n",
    "        return 0\n",
    "    dp = [[0] * (len(y) + 1) for _ in range(len(x) + 1)]\n",
    "    for i in range(1, len(x) + 1):\n",
    "        for j in range(1, len(y) + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def compute_rouge_l_multi(predicted_answers, truths):\n",
    "    def compute_rouge_l(predicted, truth):\n",
    "        \"\"\"计算单个预测答案与单个真实答案之间的ROUGE-L分数。\"\"\"\n",
    "        lcs = lcs_length(predicted, truth)\n",
    "        if lcs == 0:\n",
    "            return 0\n",
    "        precision = lcs / len(predicted)\n",
    "        recall = lcs / len(truth)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        return f1\n",
    "    \n",
    "    rouge_l_scores = []\n",
    "    for predicted in predicted_answers:  # 直接处理每个预测答案文本\n",
    "        # 计算当前预测答案与每个真实答案之间的ROUGE-L分数，并取最大值\n",
    "        scores_for_this_answer = [compute_rouge_l(predicted, truth) for truth in truths]\n",
    "        rouge_l_scores.append(max(scores_for_this_answer))\n",
    "    \n",
    "    return np.mean(rouge_l_scores) if rouge_l_scores else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "757c6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"question\": \"Who is the famed chronicler of the Mao era who finished writing a history of the Cultural Revolution?\",\n",
    "        \"answers\": [\"Yang Jisheng\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the title of Yang Jisheng's book about the Cultural Revolution?\",\n",
    "        \"answers\": [\"The World Turned Upside Down\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In which year did Xi Jinping come to power in China?\",\n",
    "        \"answers\": [\"2012\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What was Yang Jisheng's role during the early phase of the Cultural Revolution?\",\n",
    "        \"answers\": [\"He was a university student in Beijing who immersed himself in the early phase.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is described as 'historical nihilism' by the Chinese government?\",\n",
    "        \"answers\": [\"Delving into events like the Cultural Revolution, described as subversive to corrode the party’s authority.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List two challenges Yang Jisheng faced while writing his historical works.\",\n",
    "        \"answers\": [\"He was warned against publishing his book and barred from traveling to the United States; he was told not to discuss the book with foreign media.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why did Yang Jisheng decide to write a book about the Cultural Revolution?\",\n",
    "        \"answers\": [\"To expose lies and restore the truth.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why was Yang Jisheng advised not to discuss his book with foreign media after its publication?\",\n",
    "        \"answers\": [\"The article implies there's political pressure, but does not provide a specific reason.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many people were killed during the Cultural Revolution, and what does this reflect?\",\n",
    "        \"answers\": [\"Perhaps a million or more people were killed, reflecting the extreme turmoil and bloodshed of that period.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the name of Yang Jisheng's other book about the famine caused by the Great Leap Forward?\",\n",
    "        \"answers\": [\"Tombstone.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which publishing company plans to publish an abridged English version of 'The World Turned Upside Down' in 2019?\",\n",
    "        \"answers\": [\"Farrar, Straus and Giroux.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What year did the Cultural Revolution begin?\",\n",
    "        \"answers\": [\"1966\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How did Yang Jisheng participate in the Cultural Revolution?\",\n",
    "        \"answers\": [\"He threw himself into the early phase when Mao unleashed student radicals.\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What does Yang Jisheng aim to achieve with his writing, as mentioned in his book on the Cultural Revolution?\",\n",
    "        \"answers\": [\"To expose lies and restore the truth.\"]\n",
    "    },    {\n",
    "        \"question\": 'Why has Hong Kong been a significant location for the publication of books like The World Turned Upside Down?',\n",
    "        \"answers\": [\"Because it offers much greater freedom than is found in mainland China, allowing for the publication of books banned in the mainland.\"]\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "916b2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answers = {\n",
    "    \"fact_based\": [\n",
    "        {\n",
    "            \"question\": \"What Netflix series is a reboot of a Norman Lear sitcom that discusses class divide?\",\n",
    "            \"answer\": \"One Day at a Time\",\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Who was the American ambassador to the United Nations who issued a warning to allies and rivals in her first remarks?\",\n",
    "            \"answer\": \"Nikki R. Haley\",\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"In which year did Xi Jinping come to power in China?\",\n",
    "            \"answer\": [\"2012\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the title of Yang Jisheng's book about the Cultural Revolution?\",\n",
    "            \"answer\": [\"The World Turned Upside Down\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What year did the Cultural Revolution begin?\",\n",
    "            \"answer\": [\"1966\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the name of Yang Jisheng's other book about the famine caused by the Great Leap Forward?\",\n",
    "            \"answer\": [\"Tombstone\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Which publishing company plans to publish an abridged English version of 'The World Turned Upside Down' in 2019?\",\n",
    "            \"answer\": [\"Farrar, Straus and Giroux\"],\n",
    "            \"article_id\": 494\n",
    "        }\n",
    "    ],\n",
    "    \"explanation_based\": [\n",
    "        {\n",
    "            \"question\": \"How does 'One Day at a Time' reflect the issue of class divide in its narrative?\",\n",
    "            \"answer\": \"The show reflects the class divide by showcasing a family that is closer to the lower side of the economic spectrum, discussing real-life economic struggles within a sitcom format.\",\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What was the main message Nikki R. Haley conveyed in her first remarks at the United Nations?\",\n",
    "            \"answer\": \"The main message was that the Trump administration would hold to account those who do not back the United States, signaling a change in the way the U.S. interacts with the UN.\",\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Who is the famed chronicler of the Mao era who finished writing a history of the Cultural Revolution?\",\n",
    "            \"answer\": [\"Yang Jisheng\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What was Yang Jisheng's role during the early phase of the Cultural Revolution?\",\n",
    "            \"answer\": [\"He was a university student in Beijing who immersed himself in the early phase.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is described as 'historical nihilism' by the Chinese government?\",\n",
    "            \"answer\": [\"Delving into events like the Cultural Revolution, described as subversive to corrode the party’s authority.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why did Yang Jisheng decide to write a book about the Cultural Revolution?\",\n",
    "            \"answer\": [\"To expose lies and restore the truth.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why was Yang Jisheng advised not to discuss his book with foreign media after its publication?\",\n",
    "            \"answer\": [\"The article implies there's political pressure, but does not provide a specific reason.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How many people were killed during the Cultural Revolution, and what does this reflect?\",\n",
    "            \"answer\": [\"Perhaps a million or more people were killed, reflecting the extreme turmoil and bloodshed of that period.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How did Yang Jisheng participate in the Cultural Revolution?\",\n",
    "            \"answer\": [\"He threw himself into the early phase when Mao unleashed student radicals.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What does Yang Jisheng aim to achieve with his writing, as mentioned in his book on the Cultural Revolution?\",\n",
    "            \"answer\": [\"To expose lies and restore the truth.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why has Hong Kong been a significant location for the publication of books like 'The World Turned Upside Down'?\",\n",
    "            \"answer\": [\"Because it offers much greater freedom than is found in mainland China, allowing for the publication of books banned in the mainland.\"],\n",
    "            \"article_id\": 494\n",
    "        }\n",
    "    ],\n",
    "    \"list_based\": [\n",
    "        {\n",
    "            \"question\": \"Who are the main characters in the Netflix reboot of 'One Day at a Time'?\",\n",
    "            \"answer\": [\"Penelope\", \"Alex\", \"Lydia\", \"Elena\"],\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What are the implications of the Trump administration's stance towards the United Nations as expressed by Nikki R. Haley?\",\n",
    "            \"answer\": [\"Holding to account those who do not support the U.S.\", \"A potential reduction in U.S. funding for the UN\", \"A focus on showing strength and value in U.N. participation\"],\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"List two challenges Yang Jisheng faced while writing his historical works.\",\n",
    "            \"answer\": [\"He was warned against publishing his book and barred from traveling to the United States; he was told not to discuss the book with foreign media.\"],\n",
    "            \"article_id\": 494\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "90a8c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(test_data, qa_system_func, use_relevant_content=True):\n",
    "    f1_scores, mrr_scores, map_scores, rouge_l_scores = [], [], [], []\n",
    "\n",
    "    for item in test_data:\n",
    "        question, true_answers , true_article_ids= item[\"question\"], item[\"answers\"],item[\"article_ids\"]\n",
    "        \n",
    "        predicted_answers_with_scores = qa_system_func(question, use_relevant_content)\n",
    "        \n",
    "        predicted_answers = [ans[0] for ans in predicted_answers_with_scores]\n",
    "\n",
    "        f1 = compute_f1(predicted_answers, true_answers)\n",
    "        mrr = compute_mrr(predicted_answers, true_answers)\n",
    "        map_score = compute_map(predicted_answers, true_answers)\n",
    "        rouge_l = compute_rouge_l_multi(predicted_answers, true_answers)\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "        mrr_scores.append(mrr)\n",
    "        map_scores.append(map_score)\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "    \n",
    "    print(f\"Average F1 Score: {np.mean(f1_scores)}\")\n",
    "    print(f\"Average MRR: {np.mean(mrr_scores)}\")\n",
    "    print(f\"Average MAP: {np.mean(map_scores)}\")\n",
    "    print(f\"Average ROUGE-L: {np.mean(rouge_l_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bdc69939",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mquestions_answers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "313e559d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage F1 Score for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 假设你有一个questions_answers字典，已经定义了按照上面格式\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestions_answers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_system_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[109], line 32\u001b[0m, in \u001b[0;36mrun_evaluation\u001b[0;34m(test_data, qa_system_func, use_relevant_content)\u001b[0m\n\u001b[1;32m     28\u001b[0m     article_id \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m     predicted_answer \u001b[38;5;241m=\u001b[39m qa_system_func(question, article_id, use_relevant_content)\n\u001b[0;32m---> 32\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_f1_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     f1_scores\u001b[38;5;241m.\u001b[39mappend(f1)\n\u001b[1;32m     35\u001b[0m average_f1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(f1_scores) \u001b[38;5;28;01mif\u001b[39;00m f1_scores \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[109], line 5\u001b[0m, in \u001b[0;36mcompute_f1_single\u001b[0;34m(predicted, truth)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_f1_single\u001b[39m(predicted, truth):\n\u001b[1;32m      4\u001b[0m     pred_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(predicted\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m----> 5\u001b[0m     truth_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mtruth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m      6\u001b[0m     common_tokens \u001b[38;5;241m=\u001b[39m pred_tokens\u001b[38;5;241m.\u001b[39mintersection(truth_tokens)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m common_tokens:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_f1_single(predicted, truth):\n",
    "    pred_tokens = set(predicted.lower().split())\n",
    "    truth_tokens = set(truth.lower().split())\n",
    "    common_tokens = pred_tokens.intersection(truth_tokens)\n",
    "    if not common_tokens:\n",
    "        return 0.0\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(truth_tokens)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def qa_system_func(question, article_id, use_relevant_content):\n",
    "    # 这里是一个假设的函数实现，实际应用中应替换为你的问答系统逻辑\n",
    "    # 假设它总是返回问题中的最后一个词作为答案（仅用于演示）\n",
    "    return question.split()[-1]\n",
    "\n",
    "def run_evaluation(test_data, qa_system_func, use_relevant_content=True):\n",
    "    for base_type, questions in test_data.items():\n",
    "        f1_scores = []\n",
    "        \n",
    "        for item in questions:\n",
    "            question = item[\"question\"]\n",
    "            true_answer = item[\"answer\"]  # Assuming a single answer for simplicity\n",
    "            article_id = item[\"article_id\"]\n",
    "            \n",
    "            predicted_answer = qa_system_func(question, article_id, use_relevant_content)\n",
    "            \n",
    "            f1 = compute_f1_single(predicted_answer, true_answer)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        average_f1 = np.mean(f1_scores) if f1_scores else 0.0\n",
    "        print(f\"Average F1 Score for {base_type}: {average_f1:.3f}\")\n",
    "\n",
    "# 假设你有一个questions_answers字典，已经定义了按照上面格式\n",
    "# \n",
    "run_evaluation(questions_answers, qa_system_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37723630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rustl with whole content\n",
      "Average F1 Score: 0.15787558351890046\n",
      "Average MRR: 0.06666666666666667\n",
      "Average MAP: 0.06666666666666667\n",
      "Average ROUGE-L: 0.3063513571999547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Rustl with whole content')\n",
    "\n",
    "run_evaluation(test_data, auto_answer_question,use_relevant_content=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8673376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rustl with relevant content\n",
      "Average F1 Score: 0.0743491972377193\n",
      "Average MRR: 0.0\n",
      "Average MAP: 0.08080357841639846\n",
      "Average ROUGE-L: 0.2945520255253334\n"
     ]
    }
   ],
   "source": [
    "print('Rustl with relevant content')\n",
    "\n",
    "run_evaluation(test_data, auto_answer_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
