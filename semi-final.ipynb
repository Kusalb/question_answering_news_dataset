{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### Kusal Bista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb617560-ebfe-47a0-a5ee-fb6a0ec56589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data reading\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Libraries for pre-processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Libraries for information retrieval\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Libraries for data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Libraries for question answering\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import time\n",
    "from transformers import RobertaTokenizer, RobertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cde6e7-8e19-4357-8ade-60114da4174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install tabulate\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0d6e5f-384d-47c7-b959-51604a6bc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a509-a9f1-405e-8d0b-6dc96e679322",
   "metadata": {},
   "source": [
    "### 1 Reading dataset and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1474a82-79ad-4c8d-8bae-e4d4056d2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = pd.read_csv('news_dataset.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de28f0fb-9811-4b2d-96f4-63ff46825a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04327fa-2d19-4ba8-9291-984303ca5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # selecting 100 sample \n",
    "# sample_size = 100\n",
    "# if news_dataset.shape[0] >= sample_size:\n",
    "#     news_dataset_sm = news_dataset.sample(n=sample_size, random_state=42)  # Adjusting random_state for reproducibility\n",
    "#     news_dataset_sm.reset_index(drop=True, inplace=True) \n",
    "#     print(\"Sampled dataset shape:\", news_dataset_sm.shape)\n",
    "# else:\n",
    "#     print(\"Dataset size is less than the sample size. Cannot perform sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573c3a0c-0f0f-4790-a794-9a0f87613737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       1000 non-null   int64 \n",
      " 1   author   994 non-null    object\n",
      " 2   date     1000 non-null   object\n",
      " 3   year     1000 non-null   object\n",
      " 4   month    1000 non-null   object\n",
      " 5   topic    1000 non-null   object\n",
      " 6   article  1000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "news_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177652d-42ca-4e6f-ba8d-ad3a95c503b1",
   "metadata": {},
   "source": [
    "### 1.2 Handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0eccc9-7ea3-4155-be46-4373e2338b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value\n",
      "id         0\n",
      "author     6\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf22242e-51d4-48a3-b91d-58d55ca2216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing value\n",
    "news_dataset['author'] = news_dataset['author'].fillna('No author')\n",
    "# checking missing value after handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e52309-3c2c-4899-b621-263597321d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After handling missing value\n",
      "id         0\n",
      "author     0\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"After handling missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edb4773a-7d99-41fe-bed4-f10628d76eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset = news_dataset.drop_duplicates(subset=['article'], keep='first').reset_index(drop=True)\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbbed6-f57f-4686-891e-f2b9d6466935",
   "metadata": {},
   "source": [
    "### 1.3 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2c0aee-9743-46fc-8810-c8072892a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update([\"This\", \"The\", \"the\"])\n",
    "    s = \" \\[(?=.*\\d).*?\\]\" \n",
    "    # Lemmatization and removal of stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    result = []\n",
    "    for text in data:\n",
    "        # Clean text\n",
    "        # Remove non-ASCII characters\n",
    "        text = ''.join([char for char in text if ord(char) < 128])\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove question mark problems\n",
    "        text = re.sub(r'(\\s\\?)',' ',text)\n",
    "        text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "        text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "        text = re.sub(r\"\\?+\", \"?\", text)\n",
    "        text = text.strip()\n",
    "        # Lemmatization and removal of stopwords\n",
    "        processed_text = \" \".join([lemmatizer.lemmatize(word) for word in re.sub(s, \"\", text).split() if word.lower() not in stop_words])\n",
    "        result.append(processed_text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d773dd50-b4ea-441c-97ea-d077c2a98e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['processed_article'] = pre_process(news_dataset['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820cfb36-4b63-4def-be79-4844cbec48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "      <td>PARIS Islamic State driven ancient city Palmyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "      <td>Angels everywhere Mu'iz family's apartment Bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "      <td>Finally. Second Avenue subway opened New York ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "      <td>WASHINGTON time Republicans. tumultuous decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "      <td>Megyn Kelly, shift Fox News NBC host daily day...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \\\n",
       "0  PARIS  ?   When the Islamic State was about to...   \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...   \n",
       "2  Finally. The Second Avenue subway opened in Ne...   \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...   \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  PARIS Islamic State driven ancient city Palmyr...  \n",
       "1  Angels everywhere Mu'iz family's apartment Bro...  \n",
       "2  Finally. Second Avenue subway opened New York ...  \n",
       "3  WASHINGTON time Republicans. tumultuous decade...  \n",
       "4  Megyn Kelly, shift Fox News NBC host daily day...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a041b-82b8-4302-908a-45d6bc6b4774",
   "metadata": {},
   "source": [
    "#### 2 Classical retrivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bcb4141-bd9c-476b-9b6b-0c392fb41dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading spaCy model\n",
    "nlp_md = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "class TextMatchingUtility:\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset  # Dataset\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def preprocess_query(self, query):\n",
    "        # Regular expression to match text patterns\n",
    "        s = \" \\[(?=.*\\d).*?\\]\"\n",
    "\n",
    "        # Removing stopwords and Lemmatization\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words.extend([\"This\", \"The\", \"the\"])\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        result = [\" \".join([lemmatizer.lemmatize(word) for word in re.sub(s, \"\", query).split() if word not in stop_words])]\n",
    "        return result\n",
    "\n",
    "\n",
    "    def tf_idf_score(self, query, articles):    \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        # Convert to word vector\n",
    "        articles_wv = vectorizer.fit_transform(articles)\n",
    "        # Convert to word vector\n",
    "        query_wv = vectorizer.transform([query]) \n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(query_wv, articles_wv)[0]\n",
    "        return similarities\n",
    "\n",
    "    def spacy_score(self, query, articles):\n",
    "        # Convert to word vector\n",
    "        query_nlp = nlp_md(str(query))\n",
    "        # Convert to word vector\n",
    "        articles_nlp = [nlp_md(article) for article in articles]\n",
    "        # Calculate similarity\n",
    "        similarities = [query_nlp.similarity(article_nlp) for article_nlp in articles_nlp]\n",
    "        return similarities\n",
    "    \n",
    "    def get_best_sentences(self, query, article_id, word_vector, top_n=3):\n",
    "        article = self.data.loc[self.data['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        # Convert text into sentences\n",
    "        sentences_clean = tokenize.sent_tokenize(article)\n",
    "        # Calculate similarity\n",
    "        if word_vector == \"tf-idf\":\n",
    "            similarities = self.tf_idf_score(query, sentences_clean)\n",
    "        elif word_vector == \"spaCy\":\n",
    "            similarities = self.spacy_score(query, sentences_clean)\n",
    "        # Get the indices of top N scores\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "        # Get the top N sentences and their scores\n",
    "        top_sentences = [(sentences_clean[i], similarities[i]) for i in top_indices]\n",
    "        return top_sentences \n",
    "\n",
    "    def get_best_sentence(self, query, article_id, word_vector):\n",
    "        article = self.data.loc[self.data['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        # Convert text into sentences\n",
    "        sentences_clean = tokenize.sent_tokenize(article)\n",
    "        # Calculate similarity\n",
    "        if word_vector == \"tf-idf\":\n",
    "            similarities = self.tf_idf_score(query, sentences_clean)\n",
    "        elif word_vector == \"spaCy\":\n",
    "            similarities = self.spacy_score(query, sentences_clean)\n",
    "    \n",
    "        # Get the maximum score index position\n",
    "        best_idx = np.array(similarities).argmax()\n",
    "        # Get the best score\n",
    "        best_score = max(similarities)\n",
    "        # Get original data\n",
    "        for j in range(len(self.data['id'])):\n",
    "            if self.data['id'][j] == article_id:\n",
    "                topic = self.data['article'][j]\n",
    "        sentences_topic = tokenize.sent_tokenize(topic)\n",
    "        answer = sentences_topic[best_idx]\n",
    "        print(\"Article ID \", article_id)  \n",
    "        print(\"Question:\", query)\n",
    "        if best_score < 0.3:\n",
    "            print(\"No answer found\")\n",
    "        else:\n",
    "            print(\"Answer:\", answer)\n",
    "            print(\"Score\", best_score,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cbb60-87e5-4a14-9d21-b3878e6f58bf",
   "metadata": {},
   "source": [
    "### 2.1 tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a6d3ac-7791-4227-8f55-5b7d496fc184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer 1: de facto leader, Jay Y. Lee, vice chairman Samsung, questioned Thursday, according special prosecutor's office, recommended also investigated suspicion perjury.\n",
      "Score: 0.36449756195127636\n",
      "\n",
      "Answer 2: Mr. Lee effectively run Samsung, South Korea's largest conglomerate son chairman, Lee incapacitated health problems.\n",
      "Score: 0.1805434411681926\n",
      "\n",
      "Answer 3: Moon chairman pension fund, arrested last month charge illegally pressured fund back merger South Korea's health welfare minister.\n",
      "Score: 0.12484468335180934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Sample question\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id = 17574\n",
    "word_vector = 'tf-idf'\n",
    "\n",
    "top_results = tm_utility.get_best_sentences(question, article_id, word_vector, top_n=3)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "for i, (answer, score) in enumerate(top_results, 1):\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print(\"Score:\", score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e91057-d03f-464c-b23d-7644b688913a",
   "metadata": {},
   "source": [
    "### 2.2 tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f99598df-8b99-466c-83cc-95a86618fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer 1: Investigators special prosecutor's office questioned senior Samsung executive suspect bribery accusations.\n",
      "Score: 0.6452350002474918\n",
      "\n",
      "Answer 2: national pension fund's support crucial merger, analyst said helped Mr. Lee inherit control Samsung father.\n",
      "Score: 0.6324615702928353\n",
      "\n",
      "Answer 3: email contained information financial support provided Samsung, prosecutor's office said.\n",
      "Score: 0.6281308975156643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Sample question\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id = 17574\n",
    "word_vector = 'spaCy'\n",
    "\n",
    "top_results = tm_utility.get_best_sentences(question, article_id, word_vector, top_n=3)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "for i, (answer, score) in enumerate(top_results, 1):\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print(\"Score:\", score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8c3bc-ae47-418c-9cf8-ce3a9b4c548d",
   "metadata": {},
   "source": [
    "### Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f811a17c-cfd6-4a31-8af1-c0debaf1b335",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test questions\n",
    "test_questions = [\n",
    "    {'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'Who is the de facto head of Samsung being questioned for bribery?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'What scandal led to President Park\\'s impeachment?', 'answer': 'corruption scandal'},\n",
    "    {'query': 'What is the name of Samsung\\'s vice chairman?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'What is the name of the special prosecutor investigating the corruption scandal?', 'answer': '[SEP]'},\n",
    "    {'query': 'Who is on trial at the Constitutional Court?', 'answer': 'Ms. Park'},\n",
    "    {'query': 'What is the name of the special prosecutor\\'s office spokesman?', 'answer': 'Lee'},\n",
    "    {'query': 'What charges were filed against Ms. Choi by state prosecutors?', 'answer': 'coercing 53 big businesses'},\n",
    "    {'query': 'What organization\\'s support was crucial for the merger of two Samsung affiliates?', 'answer': 'National Pension Service'},\n",
    "    {'query': 'What amount did Samsung contribute to Ms. Choi\\'s winter sports program?', 'answer': '$1.3 million'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ba4fc0-1ba8-48a1-b172-20381d0b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestUtility:\n",
    "    def __init__(self, text_matching_utility, test_questions):\n",
    "        self.text_matching_utility = text_matching_utility\n",
    "        self.test_questions = test_questions\n",
    "\n",
    "    def evaluate_mrr(self, article_id, word_vector):\n",
    "        reciprocal_ranks = []\n",
    "\n",
    "        for question_data in self.test_questions:\n",
    "            query = question_data['query']\n",
    "            true_answer = question_data['answer']\n",
    "\n",
    "            # Get the best sentence from the text matching utility\n",
    "            best_sentence = self.text_matching_utility.get_best_sentence(query, article_id, word_vector)\n",
    "\n",
    "            # If no answer found, skip this question\n",
    "            if not best_sentence:\n",
    "                continue\n",
    "\n",
    "            # Check if the true answer is in the best sentence\n",
    "            if true_answer in best_sentence:\n",
    "                rank = best_sentence.index(true_answer) + 1  # Rank of the true answer\n",
    "                reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "        # Calculate MRR\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "        return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5beb52f1-45c9-44cf-8431-c629794a8ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID  17574\n",
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: A special prosecutor investigating the corruption scandal that led to President Park  ?s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect.\n",
      "Score 0.36449756195127636 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is the de facto head of Samsung being questioned for bribery?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.40674978209780877 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What scandal led to President Park's impeachment?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.46819122789633294 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of Samsung's vice chairman?\n",
      "Answer: A special prosecutor investigating the corruption scandal that led to President Park  ?s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect.\n",
      "Score 0.36449756195127636 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor investigating the corruption scandal?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.43810532891506093 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is on trial at the Constitutional Court?\n",
      "Answer: Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly?s vote to impeach her last month.\n",
      "Score 0.49466520075934983 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor's office spokesman?\n",
      "Answer: ?\n",
      "Score 0.4005923802428597 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What charges were filed against Ms. Choi by state prosecutors?\n",
      "No answer found\n",
      "Article ID  17574\n",
      "Question: What organization's support was crucial for the merger of two Samsung affiliates?\n",
      "Answer: The emails contained information about the financial support provided by Samsung, the prosecutor?s office said.\n",
      "Score 0.43161217785872114 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "Answer: Samsung gave the largest donations to Ms. Choi?s foundations, totaling $17 million.\n",
      "Score 0.46543391489665975 \n",
      "\n",
      "Mean Reciprocal Rank (MRR) with spaCy word vector: 0\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TextMatchingUtility\n",
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Create an instance of TestUtility\n",
    "test_utility = TestUtility(tm_utility, test_questions)\n",
    "\n",
    "# Test with spaCy word vector and article id\n",
    "article_id = 17574  # Replace with appropriate article ID\n",
    "mrr = test_utility.evaluate_mrr(article_id, word_vector='tf-idf')\n",
    "print(\"Mean Reciprocal Rank (MRR) with spaCy word vector:\", mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58aafc9f-6c3e-4a0b-9353-7a7571b58098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID  17574\n",
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: He is expected to be asked whether   donations that Samsung made to two foundations controlled by Choi   a longtime friend of the president, amounted to bribes, and what role, if any, he played in the decision to give the money.\n",
      "Score 0.6452350002474918 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is the de facto head of Samsung being questioned for bribery?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.737722794448654 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What scandal led to President Park's impeachment?\n",
      "Answer: Neither Samsung nor Mr. Lee responded immediately to the announcement on Wednesday.\n",
      "Score 0.7442539702783805 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of Samsung's vice chairman?\n",
      "Answer: The emails contained information about the financial support provided by Samsung, the prosecutor?s office said.\n",
      "Score 0.687793324204307 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor investigating the corruption scandal?\n",
      "Answer: Last month, Mr. Lee testified at a National Assembly hearing that he was not involved in the decision by Samsung to make the donations.\n",
      "Score 0.7392913894151909 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is on trial at the Constitutional Court?\n",
      "Answer: Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly?s vote to impeach her last month.\n",
      "Score 0.6484108171985002 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor's office spokesman?\n",
      "Answer: He is expected to be asked whether   donations that Samsung made to two foundations controlled by Choi   a longtime friend of the president, amounted to bribes, and what role, if any, he played in the decision to give the money.\n",
      "Score 0.7626621232689227 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What charges were filed against Ms. Choi by state prosecutors?\n",
      "Answer: The special prosecutor?s office said it had evidence that Mr. Lee had ?received a request for bribery from the president and ordered Samsung subsidiaries to send bribes to destinations designated by the president.\n",
      "Score 0.7104221918252797 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What organization's support was crucial for the merger of two Samsung affiliates?\n",
      "Answer: Mr. Lee effectively runs Samsung, South Korea?s largest conglomerate he is the son of its chairman, Lee   who has been incapacitated with health problems.\n",
      "Score 0.7972569440782834 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "Answer: The emails contained information about the financial support provided by Samsung, the prosecutor?s office said.\n",
      "Score 0.7239691215976823 \n",
      "\n",
      "Mean Reciprocal Rank (MRR) with spaCy word vector: 0\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TextMatchingUtility\n",
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Create an instance of TestUtility\n",
    "test_utility = TestUtility(tm_utility, test_questions)\n",
    "\n",
    "# Test with spaCy word vector and article id\n",
    "article_id = 17574  # Replace with appropriate article ID\n",
    "mrr = test_utility.evaluate_mrr(article_id, word_vector='spaCy')\n",
    "print(\"Mean Reciprocal Rank (MRR) with spaCy word vector:\", mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c730cb-d95a-41a8-a5bb-f68bc1e1e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnsweringSystem:\n",
    "    def __init__(self, model_name='deepset/bert-base-cased-squad2'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "    def answer_question(self, question, article_id):\n",
    "        passage = news_dataset.loc[news_dataset['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        inputs = self.tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation=True, truncation_strategy='longest_first')\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        start_index = torch.argmax(start_logits)\n",
    "        end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "        input_tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "        for i, token in enumerate(answer_tokens):\n",
    "            if token == self.tokenizer.cls_token_id:\n",
    "                start_index += 1\n",
    "            elif token == self.tokenizer.sep_token_id:\n",
    "                end_index -= 1\n",
    "        answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "        answer = self.tokenizer.decode(answer_tokens)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cd8918a-0e4d-4477-a33a-b4ca9dd6bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestUtility:\n",
    "    def __init__(self, test_questions):\n",
    "        self.test_questions = test_questions\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(test_questions, predicted_labels):\n",
    "        if len(test_questions) != len(predicted_labels):\n",
    "            raise ValueError(\"Length of test_questions and predicted_labels must be the same.\")\n",
    "\n",
    "        correct = 0\n",
    "        total = len(test_questions)\n",
    "        for i in range(total):\n",
    "            correct_answer = test_questions[i]['answer'].lower()\n",
    "            predicted_label = predicted_labels[i].lower()\n",
    "            correct_answer = correct_answer.replace(\" \", \"\")\n",
    "            print(correct_answer,predicted_label)\n",
    "            if correct_answer in predicted_label:\n",
    "                correct += 1\n",
    "        if total == 0:\n",
    "            return 0  # Return 0 if there are no test questions\n",
    "        return correct / total\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_reciprocal_rank(test_questions, predicted_labels):\n",
    "        rr_sum = 0\n",
    "        total = len(test_questions)\n",
    "        for i in range(total):\n",
    "            correct_answer = test_questions[i]['answer'].lower()\n",
    "            predicted_labels_lower = predicted_labels[i].lower()\n",
    "            correct_answer = correct_answer.replace(\" \", \"\")\n",
    "            if correct_answer in predicted_labels_lower:\n",
    "                rr_sum += 1 / (predicted_labels_lower.index(correct_answer) + 1)\n",
    "        return rr_sum / total if total != 0 else 0\n",
    "\n",
    "    def evaluate_performance(self, predicted_labels):\n",
    "        acc = self.accuracy(self.test_questions, predicted_labels)\n",
    "        mrr = self.mean_reciprocal_rank(self.test_questions, predicted_labels)\n",
    "\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Mean Reciprocal Rank:\", mrr)\n",
    "\n",
    "    def get_predicted_labels(self, article_id, qa_model):\n",
    "        start_time = time.time()\n",
    "        answers = []\n",
    "        print_query = []\n",
    "        for index, question in enumerate(self.test_questions):\n",
    "            query = qa_model.answer_question(question['query'], article_id) \n",
    "            predicted_labels = query.replace(\" \", \"\")\n",
    "            answers.append(predicted_labels)\n",
    "            print_query.append(query)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(\"Execution time:\", execution_time, \"seconds\")\n",
    "        return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71f27a62-f22e-4154-bfbb-3234aa462caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: Jay Y. Lee\n"
     ]
    }
   ],
   "source": [
    "article_id = 17574\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "\n",
    "qa_system = QuestionAnsweringSystem()\n",
    "answer = qa_system.answer_question(question, article_id)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341fcb0b-bca3-4074-9ac4-848cbedc72fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
       " {'query': 'Who is the de facto head of Samsung being questioned for bribery?',\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': \"What scandal led to President Park's impeachment?\",\n",
       "  'answer': 'corruption scandal'},\n",
       " {'query': \"What is the name of Samsung's vice chairman?\",\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': 'What is the name of the special prosecutor investigating the corruption scandal?',\n",
       "  'answer': '[SEP]'},\n",
       " {'query': 'Who is on trial at the Constitutional Court?',\n",
       "  'answer': 'Ms. Park'},\n",
       " {'query': \"What is the name of the special prosecutor's office spokesman?\",\n",
       "  'answer': 'Lee'},\n",
       " {'query': 'What charges were filed against Ms. Choi by state prosecutors?',\n",
       "  'answer': 'coercing 53 big businesses'},\n",
       " {'query': \"What organization's support was crucial for the merger of two Samsung affiliates?\",\n",
       "  'answer': 'National Pension Service'},\n",
       " {'query': \"What amount did Samsung contribute to Ms. Choi's winter sports program?\",\n",
       "  'answer': '$1.3 million'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "700bbc91-f8ad-4dc0-9b9d-0594d05689bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3.0121560096740723 seconds\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations.alsosaiddonationvoluntary,suggestingcompanyvictimextortion,participantbribery.referencewednesdaypossibleperjurychargemr.leestemmedtestimony.specialprosecutor'sofficesaidevidencemr.leereceivedrequestbriberypresidentorderedsamsungsubsidiarysendbribedestinationdesignatedpresident.askednationalassemblyfileperjurycomplaintmr.lee,wouldauthorizespecialprosecutoropeninvestigationcharge.askedwhetherinvestigatorwouldseekarrestmr.leebriberycharges,spokesmanspecialprosecutor'soffice,leesaid,possibilityopen.november,stateprosecutorindictedms.choichargecoercing53bigbusinesses,includingsamsung,contribute$69milliontwofoundations\n",
      "jayy.lee jayy.lee\n",
      "[sep] jayy.lee\n",
      "ms.park jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations\n",
      "lee jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations\n",
      "coercing53bigbusinesses twofoundations\n",
      "nationalpensionservice jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations.alsosaiddonationvoluntary,suggestingcompanyvictimextortion,participantbribery.referencewednesdaypossibleperjurychargemr.leestemmedtestimony.specialprosecutor'sofficesaidevidencemr.leereceivedrequestbriberypresidentorderedsamsungsubsidiarysendbribedestinationdesignatedpresident.askednationalassemblyfileperjurycomplaintmr.lee,wouldauthorizespecialprosecutoropeninvestigationcharge.askedwhetherinvestigatorwouldseekarrestmr.leebriberycharges,spokesmanspecialprosecutor'soffice,leesaid,possibilityopen.november,stateprosecutorindictedms.choichargecoercing53bigbusinesses,includingsamsung,contribute$69milliontwofoundations\n",
      "$1.3million $69million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.3170212365743092\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system)\n",
    "\n",
    "# Now you can pass these predicted labels to evaluate_performance method to evaluate performance\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee88b72-d7cc-43fc-a614-935f53138d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73b1bd36-6320-49b9-bad1-64e28679399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer:  Jay Y. Lee\n"
     ]
    }
   ],
   "source": [
    "article_id = 17574\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "\n",
    "qa_system_roberta = QuestionAnsweringSystem(model_name= \"deepset/roberta-base-squad2\")\n",
    "answer = qa_system_roberta.answer_question(question, article_id)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0a31a0b-e968-4e60-ba0e-d1eecd51e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jay Y. Lee', 'Jay Y. Lee', 'corruption scandal', 'Jay Y. Lee', '[SEP]', 'Ms. Park', 'Lee', 'coercing 53 big businesses', 'National Pension Service', '$1.3 million']\n"
     ]
    }
   ],
   "source": [
    "true_labels = [item['answer'] for item in test_questions]\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eeef873-90ae-4a73-a23f-c9f6edd8e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3.0620510578155518 seconds\n",
      "['Jay Y. Lee', 'Jay Y. Lee', 'corruption scandal', 'Jay Y. Lee', '[SEP]', 'Ms. Park', 'Lee', 'coercing 53 big businesses', 'National Pension Service', '$1.3 million']\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal corruption\n",
      "jayy.lee jayy.lee\n",
      "[sep] \n",
      "ms.park \n",
      "lee \n",
      "coercing53bigbusinesses coercing53bigbusinesses\n",
      "nationalpensionservice nationalpensionservice\n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system_roberta)\n",
    "\n",
    "# Now you can pass these predicted labels to evaluate_performance method to evaluate performance\n",
    "print(true_labels)\n",
    "test_utility.evaluate_performance(predicted_labels)# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system_roberta)\n",
    "\n",
    "# Now you can pass these predicted labels to evaluate_performance method to evaluate performance\n",
    "print(true_labels)\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37c901fa-2ac1-457f-b5f0-9215604fb3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6c557d3-3758-407e-8d81-3c5d1c67de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class QuestionAnsweringModel:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def tokenize(self, question, answer_text):\n",
    "        '''\n",
    "        Tokenizes the input question and answer_text and sets the segment IDs.\n",
    "        '''\n",
    "        # Apply the tokenizer to the encode text, treating them as a question, answer_text pair.\n",
    "        input_ids = self.tokenizer.encode(question, answer_text, max_length=512, truncation=True, truncation_strategy='only_second')\n",
    "\n",
    "        # Report how long the input sequence is.\n",
    "        # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "        # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "        sep_index = input_ids.index(self.tokenizer.sep_token_id)\n",
    "\n",
    "        # The number of segment A tokens includes the [SEP] token itself.\n",
    "        num_seg_a = sep_index + 1\n",
    "\n",
    "        # The remainder are segment B.\n",
    "        num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "        # Construct the list of 0s and 1s.\n",
    "        segment_ids = [0] * num_seg_a + [1] * num_seg_b\n",
    "\n",
    "        # There should be a segment_id for every input token.\n",
    "        assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "        return input_ids, segment_ids\n",
    "\n",
    "    def evaluate(self, input_ids, segment_ids):\n",
    "        '''\n",
    "        Evaluates the input question and answer_text using the model.\n",
    "        '''\n",
    "        # Run the question through the model.\n",
    "        model_scores = self.model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids])) \n",
    "        start_scores = model_scores.start_logits\n",
    "        end_scores = model_scores.end_logits\n",
    "\n",
    "        return start_scores, end_scores\n",
    "\n",
    "    def reconstruct_answer(self, input_ids, start_scores, end_scores):\n",
    "        '''\n",
    "        Reconstructs the answer from the model's output.\n",
    "        '''\n",
    "        # Find the tokens with the highest `start` and `end` scores.\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores)\n",
    "\n",
    "        # Get the string versions of the input tokens.\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        # Start with the first token.\n",
    "        answer = tokens[answer_start]\n",
    "\n",
    "        # Select the remaining answer tokens and join them with whitespace.\n",
    "        for i in range(answer_start + 1, answer_end + 1):\n",
    "            # If it's a subword token, then recombine it with the previous token.\n",
    "            if tokens[i][0:2] == '##':\n",
    "                answer += tokens[i][2:]\n",
    "            # Otherwise, add a space then the token.\n",
    "            else:\n",
    "                answer += ' ' + tokens[i]\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def answer_question(self, question, article_id):\n",
    "        '''\n",
    "        Takes a `question` string and an `answer_text` string (which contains the\n",
    "        answer), and identifies the words within the `answer_text` that are the\n",
    "        answer. Prints them out.\n",
    "        '''\n",
    "        #get article\n",
    "        answer_text = news_dataset.loc[news_dataset['id'] == article_id, 'processed_article'].iloc[0]\n",
    "\n",
    "        # Tokenize\n",
    "        input_ids, segment_ids = self.tokenize(question, answer_text)\n",
    "\n",
    "        # Evaluate\n",
    "        start_scores, end_scores = self.evaluate(input_ids, segment_ids)\n",
    "\n",
    "        # Reconstruct Answer\n",
    "        answer = self.reconstruct_answer(input_ids, start_scores, end_scores)\n",
    "\n",
    "        return answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "201ef03f-a4e1-4ba7-bb6d-e8a798f1c250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: jay y . lee\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "qa_model = QuestionAnsweringModel(model, tokenizer)\n",
    "\n",
    "# Define your question and article ID\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id =17574 \n",
    "\n",
    "# Call the answer_question method to get the answer\n",
    "answer = qa_model.answer_question(question, article_id)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed93e50b-267d-428a-95f2-cb6203bae6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jayy.lee', 'jayy.lee', 'corruption', 'jayy.lee', '[SEP]', 'ms.park', 'lee', 'coercing53bigbusinesses', \"[CLS]whatorganization'ssupportwascrucialforthemergeroftwosamsungaffiliates?[SEP]\", '$1.3million']\n"
     ]
    }
   ],
   "source": [
    "def predicted_labels(test_questions):\n",
    "    start_time = time.time()\n",
    "    answers = []\n",
    "    article_id = 17574\n",
    "    for index, question in enumerate(test_questions):\n",
    "        query = qa_model.answer_question(question['query'], article_id)\n",
    "        predicted_labels = query.replace(\" \", \"\")\n",
    "        answers.append(predicted_labels)\n",
    "    return answers\n",
    "predicted_labels = predicted_labels(test_questions)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3dfd69a-5569-4eef-b04f-23460682ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
       " {'query': 'Who is the de facto head of Samsung being questioned for bribery?',\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': \"What scandal led to President Park's impeachment?\",\n",
       "  'answer': 'corruption scandal'},\n",
       " {'query': \"What is the name of Samsung's vice chairman?\",\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': 'What is the name of the special prosecutor investigating the corruption scandal?',\n",
       "  'answer': '[SEP]'},\n",
       " {'query': 'Who is on trial at the Constitutional Court?',\n",
       "  'answer': 'Ms. Park'},\n",
       " {'query': \"What is the name of the special prosecutor's office spokesman?\",\n",
       "  'answer': 'Lee'},\n",
       " {'query': 'What charges were filed against Ms. Choi by state prosecutors?',\n",
       "  'answer': 'coercing 53 big businesses'},\n",
       " {'query': \"What organization's support was crucial for the merger of two Samsung affiliates?\",\n",
       "  'answer': 'National Pension Service'},\n",
       " {'query': \"What amount did Samsung contribute to Ms. Choi's winter sports program?\",\n",
       "  'answer': '$1.3 million'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcca66eb-f729-49ff-935b-6aaf463a9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jayy.lee   jayy.lee \n",
      "\n",
      "Matched\n",
      "jayy.lee   jayy.lee \n",
      "\n",
      "Matched\n",
      "corruptionscandal   corruption \n",
      "\n",
      "jayy.lee   jayy.lee \n",
      "\n",
      "Matched\n",
      "[sep]   [sep] \n",
      "\n",
      "Matched\n",
      "ms.park   ms.park \n",
      "\n",
      "Matched\n",
      "lee   lee \n",
      "\n",
      "Matched\n",
      "coercing53bigbusinesses   coercing53bigbusinesses \n",
      "\n",
      "Matched\n",
      "nationalpensionservice   [cls]whatorganization'ssupportwascrucialforthemergeroftwosamsungaffiliates?[sep] \n",
      "\n",
      "$1.3million   $1.3million \n",
      "\n",
      "Matched\n",
      "Accuracy: 0.8\n",
      "Mean Reciprocal Rank: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_model)\n",
    "\n",
    "# Now you can pass these predicted labels to evaluate_performance method to evaluate performance\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
