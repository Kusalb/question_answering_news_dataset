{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### Kusal Bista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb617560-ebfe-47a0-a5ee-fb6a0ec56589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for reading data\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Libraries for pre-processing\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Libraries for information retrieval\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Libraries for data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20cde6e7-8e19-4357-8ade-60114da4174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install tabulate\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d0d6e5f-384d-47c7-b959-51604a6bc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\a1881044\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a509-a9f1-405e-8d0b-6dc96e679322",
   "metadata": {},
   "source": [
    "### 1 Reading dataset and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1474a82-79ad-4c8d-8bae-e4d4056d2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = pd.read_csv('news_dataset.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de28f0fb-9811-4b2d-96f4-63ff46825a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573c3a0c-0f0f-4790-a794-9a0f87613737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       1000 non-null   int64 \n",
      " 1   author   994 non-null    object\n",
      " 2   date     1000 non-null   object\n",
      " 3   year     1000 non-null   object\n",
      " 4   month    1000 non-null   object\n",
      " 5   topic    1000 non-null   object\n",
      " 6   article  1000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "news_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177652d-42ca-4e6f-ba8d-ad3a95c503b1",
   "metadata": {},
   "source": [
    "### 1.2 Handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0eccc9-7ea3-4155-be46-4373e2338b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value\n",
      "id         0\n",
      "author     6\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf22242e-51d4-48a3-b91d-58d55ca2216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing value\n",
    "news_dataset['author'] = news_dataset['author'].fillna('No author')\n",
    "# checking missing value after handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71e52309-3c2c-4899-b621-263597321d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After handling missing value\n",
      "id         0\n",
      "author     0\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"After handling missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1b07bf4-1ba1-4a20-84a3-1c4e633169e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset = news_dataset.drop_duplicates(subset=['article'], keep='first').reset_index(drop=True)\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e2c0aee-9743-46fc-8810-c8072892a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    # Define stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update([\"This\", \"The\", \"the\"])\n",
    "\n",
    "    s = \" \\[(?=.*\\d).*?\\]\" \n",
    "\n",
    "    # Lemmatization and removal of stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    result = []\n",
    "    for text in data:\n",
    "        # Clean text\n",
    "        # Remove non-ASCII characters\n",
    "        text = ''.join([char for char in text if ord(char) < 128])\n",
    "\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        # Remove question mark problems\n",
    "        text = re.sub(r'(\\s\\?)',' ',text)\n",
    "        text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "        text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "        text = re.sub(r\"\\?+\", \"?\", text)\n",
    "        text = text.strip()\n",
    "\n",
    "        # Lemmatization and removal of stopwords\n",
    "        processed_text = \" \".join([lemmatizer.lemmatize(word) for word in re.sub(s, \"\", text).split() if word.lower() not in stop_words])\n",
    "\n",
    "        result.append(processed_text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d773dd50-b4ea-441c-97ea-d077c2a98e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['processed_article'] = pre_process(news_dataset['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "820cfb36-4b63-4def-be79-4844cbec48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "      <td>PARIS Islamic State driven ancient city Palmyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "      <td>Angels everywhere Mu'iz family's apartment Bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "      <td>Finally. Second Avenue subway opened New York ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "      <td>WASHINGTON time Republicans. tumultuous decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "      <td>Megyn Kelly, shift Fox News NBC host daily day...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \\\n",
       "0  PARIS  ?   When the Islamic State was about to...   \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...   \n",
       "2  Finally. The Second Avenue subway opened in Ne...   \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...   \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  PARIS Islamic State driven ancient city Palmyr...  \n",
       "1  Angels everywhere Mu'iz family's apartment Bro...  \n",
       "2  Finally. Second Avenue subway opened New York ...  \n",
       "3  WASHINGTON time Republicans. tumultuous decade...  \n",
       "4  Megyn Kelly, shift Fox News NBC host daily day...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a6f0031-a158-4100-9eaf-a19842758203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(data_index, data_text, chunk_size, chunk_overlap):\n",
    "    # Initialize a list to store chunked text\n",
    "    chunked_texts = []\n",
    "    # Iterate through each text in the input data\n",
    "    for idx, text in enumerate(data_text):\n",
    "        words = text.split()\n",
    "        # Chunk the text data\n",
    "        for i in range(0, len(words), chunk_size - chunk_overlap):\n",
    "            chunk = ' '.join(words[i:i+chunk_size])\n",
    "            chunked_texts.append((str(data_index[idx]) + str(i), chunk))\n",
    "\n",
    "    # Convert the list of chunked text into a DataFrame\n",
    "    chunk_df = pd.DataFrame(chunked_texts, columns=['id', 'processed_article'])\n",
    "    return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7d54a09-f6e4-4750-b759-927fdc167410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_chunk_size = 100\n",
    "train_overlap_size = 50\n",
    "data_chunk_train = chunk_text(news_dataset[:5]['id'], news_dataset[:5]['processed_article'], train_chunk_size, train_overlap_size)\n",
    "\n",
    "# Create testing dataset\n",
    "test_chunk_size = 500\n",
    "test_overlap_size = 50\n",
    "data_chuck_test = news_dataset[5:].reset_index(drop=True)\n",
    "data_chuck_test = chunk_text(data_chuck_test['id'], data_chuck_test['processed_article'], test_chunk_size, test_overlap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89a96fe8-ae31-4558-ad45-d8c963396a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3bad554-99cc-482f-96a1-e436565f00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize data\n",
    "def vectorize_data(text_list):\n",
    "    encoded_data = model.encode(text_list)\n",
    "    return np.asarray(encoded_data.astype('float32'))\n",
    "\n",
    "encoded_data_train = vectorize_data(data_chunk_train['processed_article'].tolist())\n",
    "encoded_data_test = vectorize_data(data_chuck_test['processed_article'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e6ee90a-ef73-4ce0-a006-20b7e80abb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "encoded_data = np.random.rand(100, 768)  # Replace this with your actual encoded data\n",
    "data_chunk = data_chuck_test  # Replace this with your actual data chunk\n",
    "\n",
    "# Save vector database\n",
    "index = {'index': encoded_data, 'ids': np.array(range(0, len(data_chunk)))}\n",
    "\n",
    "# Save index using pickle\n",
    "with open('data_article_index.pkl', 'wb') as f:\n",
    "    pickle.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7868028f-6702-40f7-864a-8318751fb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Who is the author of the memoir \"Nicotine\"?',\n",
    "             'What skills are inmates learning in the innovative program at Lecce Penitentiary?',\n",
    "             'Who surrendered to the authorities for changing the Hollywood sign to \"Hollyweed\"?',\n",
    "             'What is the name of the journalist and archivist who advocated for the online publication of the C.I.A. files?',\n",
    "             'Which leader of the fringe movement embracing white nationalism was punched in the face during the protests in Washington?',\n",
    "             'Who narrated the documentary \"I Am Not Your Negro\"?',\n",
    "             'Who is the billionaire restaurant owner nominated to head the Labor Department?',\n",
    "             \"Who is the federal judge that ordered President Trump's golf resort to pay $5.7 million for refusing to refund deposits to members?\",\n",
    "             'What business relationship between Donald Trump and Elon Musk surprised many people?',\n",
    "             \"Who vowed to take executive action on a nearly daily basis to unravel his predecessor's legacy and begin enacting his own agenda?\",\n",
    "             \"What was Hubert Edward Spires's discharge status changed to by the Air Force Board for the Correction of Military Records?\",\n",
    "             'What advice was given to Mr. LaCasse regarding restructuring his student loans to aid his retirement savings?',\n",
    "             \"What word did The New York Times ultimately choose to describe President Trump's assertion about illegal voting in the headline?\",\n",
    "             \"What is the title of Vladimir Nabokov's controversial novel published in 1955?\",\n",
    "             \"What adversity have the Mu'iz family faced?\",\n",
    "             \"Why did Jennifer Holliday decide to withdraw from performing at the inauguration concert for Donald Trump?\",\n",
    "             \"What did Donald Trump concede for the first time during his news conference at Trump Tower?\",\n",
    "             \"Who founded Airline Ambassadors International?\",\n",
    "             \"Where was the suspect in the Istanbul nightclub attack arrested?\",\n",
    "             \"What significant event involving Emmett Till occurred on August 28, 1955?\",\n",
    "             \"Who recently sold his personal papers to the Beinecke Rare Book Manuscript Library at Yale University?\",\n",
    "             \"Who was Don Ciccone, and what significant roles did he play in the music industry?\",\n",
    "             \"Who is celebrating their sapphire jubilee, marking 65 years on the British throne?\",\n",
    "             \"Who performed a soulful rendition of 'America the Beautiful' at the Lincoln Memorial concert?\",\n",
    "             \"Who challenged Germany's national atonement for the Holocaust and Nazi crimes during a speech in Dresden?\",\n",
    "             \"What trend did Jerry Silverman, the president and chief executive of the Jewish Federations of North America, describe as disturbing?\",\n",
    "             \"What significant event in Tom Casperson's political career was influenced by the DeVos family's opposition?\",\n",
    "             \"Who has been involved in financial mismanagement issues according to the article?\",\n",
    "             \"Who won the Australian Open for the fifth time, becoming the oldest man to win a Grand Slam singles title in 45 years?\",\n",
    "             \"What significant event occurred in Greenwood, Miss., in 1963 that was documented by Claude Sitton?\",\n",
    "             \"Who announced their resignation from Sony's entertainment division to focus on Snapchat?\",\n",
    "             \"What was the incident involving a Palestinian driver and Israeli soldiers that occurred in Jerusalem?\",\n",
    "             \"How many people did Governor Peter Shumlin of Vermont pardon for misdemeanor marijuana convictions?\",\n",
    "             \"Who attended the Women's March on Washington?\",\n",
    "             \"What was the outcome of the 1998 Australian Open match between Venus and Serena Williams?\",\n",
    "             \"What role did Steve Bannon receive in the National Security Council?\",\n",
    "             \"What did President Trump emphasize in his Inaugural Address?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a711c16b-afdb-4142-a8bd-6f44644cf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = [17552, 17382, 17547, 17778, 17841, 18228, 18443, 18170, 17980, 17838, 17544,\n",
    "          17434, 17972, 18163, 17292, 17645, 17556, 18382, 17701, 18084, 17372, 18054,\n",
    "          18352, 17787, 17765, 17502, 17500, 18174, 18130, 18282, 17629, 17507, 17406,\n",
    "          17863, 17990, 18122, 17837]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f55a1b84-acf1-4128-91a4-308cebd24131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = []\n",
    "for i in range(len(questions)):\n",
    "    test_data.append([doc_id[i], questions[i]])\n",
    "test_data = pd.DataFrame(test_data, columns=['doc_id', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab5c227c-c9ff-4c10-9731-0c927fa11404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17552</td>\n",
       "      <td>Who is the author of the memoir \"Nicotine\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17382</td>\n",
       "      <td>What skills are inmates learning in the innova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17547</td>\n",
       "      <td>Who surrendered to the authorities for changin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17778</td>\n",
       "      <td>What is the name of the journalist and archivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17841</td>\n",
       "      <td>Which leader of the fringe movement embracing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18228</td>\n",
       "      <td>Who narrated the documentary \"I Am Not Your Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18443</td>\n",
       "      <td>Who is the billionaire restaurant owner nomina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18170</td>\n",
       "      <td>Who is the federal judge that ordered Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17980</td>\n",
       "      <td>What business relationship between Donald Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17838</td>\n",
       "      <td>Who vowed to take executive action on a nearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17544</td>\n",
       "      <td>What was Hubert Edward Spires's discharge stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17434</td>\n",
       "      <td>What advice was given to Mr. LaCasse regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17972</td>\n",
       "      <td>What word did The New York Times ultimately ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18163</td>\n",
       "      <td>What is the title of Vladimir Nabokov's contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17292</td>\n",
       "      <td>What adversity have the Mu'iz family faced?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17645</td>\n",
       "      <td>Why did Jennifer Holliday decide to withdraw f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17556</td>\n",
       "      <td>What did Donald Trump concede for the first ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18382</td>\n",
       "      <td>Who founded Airline Ambassadors International?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17701</td>\n",
       "      <td>Where was the suspect in the Istanbul nightclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18084</td>\n",
       "      <td>What significant event involving Emmett Till o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17372</td>\n",
       "      <td>Who recently sold his personal papers to the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18054</td>\n",
       "      <td>Who was Don Ciccone, and what significant role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18352</td>\n",
       "      <td>Who is celebrating their sapphire jubilee, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17787</td>\n",
       "      <td>Who performed a soulful rendition of 'America ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17765</td>\n",
       "      <td>Who challenged Germany's national atonement fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17502</td>\n",
       "      <td>What trend did Jerry Silverman, the president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17500</td>\n",
       "      <td>What significant event in Tom Casperson's poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18174</td>\n",
       "      <td>Who has been involved in financial mismanageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18130</td>\n",
       "      <td>Who won the Australian Open for the fifth time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18282</td>\n",
       "      <td>What significant event occurred in Greenwood, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17629</td>\n",
       "      <td>Who announced their resignation from Sony's en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17507</td>\n",
       "      <td>What was the incident involving a Palestinian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17406</td>\n",
       "      <td>How many people did Governor Peter Shumlin of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17863</td>\n",
       "      <td>Who attended the Women's March on Washington?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17990</td>\n",
       "      <td>What was the outcome of the 1998 Australian Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18122</td>\n",
       "      <td>What role did Steve Bannon receive in the Nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17837</td>\n",
       "      <td>What did President Trump emphasize in his Inau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                           question\n",
       "0    17552        Who is the author of the memoir \"Nicotine\"?\n",
       "1    17382  What skills are inmates learning in the innova...\n",
       "2    17547  Who surrendered to the authorities for changin...\n",
       "3    17778  What is the name of the journalist and archivi...\n",
       "4    17841  Which leader of the fringe movement embracing ...\n",
       "5    18228  Who narrated the documentary \"I Am Not Your Ne...\n",
       "6    18443  Who is the billionaire restaurant owner nomina...\n",
       "7    18170  Who is the federal judge that ordered Presiden...\n",
       "8    17980  What business relationship between Donald Trum...\n",
       "9    17838  Who vowed to take executive action on a nearly...\n",
       "10   17544  What was Hubert Edward Spires's discharge stat...\n",
       "11   17434  What advice was given to Mr. LaCasse regarding...\n",
       "12   17972  What word did The New York Times ultimately ch...\n",
       "13   18163  What is the title of Vladimir Nabokov's contro...\n",
       "14   17292        What adversity have the Mu'iz family faced?\n",
       "15   17645  Why did Jennifer Holliday decide to withdraw f...\n",
       "16   17556  What did Donald Trump concede for the first ti...\n",
       "17   18382     Who founded Airline Ambassadors International?\n",
       "18   17701  Where was the suspect in the Istanbul nightclu...\n",
       "19   18084  What significant event involving Emmett Till o...\n",
       "20   17372  Who recently sold his personal papers to the B...\n",
       "21   18054  Who was Don Ciccone, and what significant role...\n",
       "22   18352  Who is celebrating their sapphire jubilee, mar...\n",
       "23   17787  Who performed a soulful rendition of 'America ...\n",
       "24   17765  Who challenged Germany's national atonement fo...\n",
       "25   17502  What trend did Jerry Silverman, the president ...\n",
       "26   17500  What significant event in Tom Casperson's poli...\n",
       "27   18174  Who has been involved in financial mismanageme...\n",
       "28   18130  Who won the Australian Open for the fifth time...\n",
       "29   18282  What significant event occurred in Greenwood, ...\n",
       "30   17629  Who announced their resignation from Sony's en...\n",
       "31   17507  What was the incident involving a Palestinian ...\n",
       "32   17406  How many people did Governor Peter Shumlin of ...\n",
       "33   17863      Who attended the Women's March on Washington?\n",
       "34   17990  What was the outcome of the 1998 Australian Op...\n",
       "35   18122  What role did Steve Bannon receive in the Nati...\n",
       "36   17837  What did President Trump emphasize in his Inau..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0455dc7-8bea-44e0-a311-4f19cb7e1a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1513082 , -0.13743426, -0.7632094 , ..., -0.04565372,\n",
       "        -0.36991662,  0.4084309 ],\n",
       "       [-0.07812551, -0.04014127, -0.63176763, ...,  0.03896321,\n",
       "        -0.82238185,  0.16641286],\n",
       "       [-0.20078646,  0.32540423, -0.89036834, ...,  0.5825768 ,\n",
       "        -0.34565404,  0.16913635],\n",
       "       ...,\n",
       "       [ 0.28563666,  0.00128658, -0.7693261 , ...,  0.4912801 ,\n",
       "        -0.30372304,  0.48328856],\n",
       "       [-0.1693944 ,  0.06060646, -0.5516199 , ..., -0.03478811,\n",
       "        -0.01499029,  0.3165173 ],\n",
       "       [ 0.1363754 , -0.1558264 , -0.6475471 , ...,  0.18430465,\n",
       "        -0.20248297,  0.06620441]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "751b065a-b96c-4048-b3d8-4a05a7ffcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')\n",
    "# cross_model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6', max_length=512)\n",
    "\n",
    "with open('data_article_index.pkl', 'rb') as f:\n",
    "    loaded_index = pickle.load(f)\n",
    "\n",
    "# Access loaded index\n",
    "loaded_encoded_data = loaded_index['index']\n",
    "index = loaded_index['ids']\n",
    "data_chunk = encoded_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ac381a2-96bd-4673-8f1b-c3afbaad4aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1907, 1908, 1909])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6db1c56c-f9e5-43c6-9f05-9f7a4de0ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_info(dataframe_idx, score):\n",
    "\n",
    "    '''Data should be data_chunk'''\n",
    "    info = data_chunk.iloc[dataframe_idx]\n",
    "    meta_dict = {}\n",
    "    meta_dict['id'] = info['id']\n",
    "    meta_dict['article'] = info['article']\n",
    "    meta_dict['score'] = score\n",
    "\n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e348b3ee-820a-4755-b65b-010c6544f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search(query, top_k, index, model):\n",
    "\n",
    "#     query_vector = model.encode([query])\n",
    "#     top_k = index.search(query_vector, top_k)\n",
    "\n",
    "#     top_k_ids = list(top_k[1].tolist()[0])\n",
    "#     score = list(top_k[0].tolist()[0])\n",
    "\n",
    "#     results =  [fetch_data_info(idx, score) for idx, score in zip(top_k_ids, score)]\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d283246-dd32-43b8-888d-eb13ba40cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = ''.join([char for char in text if ord(char) < 128])\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove question mark problems\n",
    "    text = re.sub(r'(\\s\\?)',' ',text)\n",
    "    text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "    text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "    text = re.sub(r\"\\?+\", \"?\", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93638612-0e31-42dc-bc72-3217cfd50c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_answer(query, query_id, document, cross_model):\n",
    "    query = clean_text(query)\n",
    "    document = clean_text(document)\n",
    "\n",
    "    # Prepare model input\n",
    "    model_input = [[query, document]]\n",
    "\n",
    "    # Predict score using cross_model\n",
    "    score = cross_model.predict(model_input)[0]\n",
    "\n",
    "    result_dataset = [{\n",
    "        'question_id': query_id,\n",
    "        'rank': 1,\n",
    "        'id': query_id // 10,  # Assuming query_id represents document ID\n",
    "        'score': score\n",
    "    }]\n",
    "\n",
    "    return result_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a253cc80-57ad-49ba-b417-6f0ea7c5d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_score(answers, queries):\n",
    "    '''answers is a list of list of ids'''\n",
    "    score = []\n",
    "    for i, answer in enumerate(answers):\n",
    "        for j, index in enumerate(answer):\n",
    "            if index == queries[i]:\n",
    "                score.append(1 / (j + 1))\n",
    "                break\n",
    "        if len(score) < (i + 1):\n",
    "            score.append(0)\n",
    "    return sum(score) / len(score) if len(score) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ad54b81-f96c-48fe-bc2f-128639013a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(answers, queries):\n",
    "    '''answers is a list of list of ids'''\n",
    "    score = []\n",
    "    for i, answer in enumerate(answers):\n",
    "        for index in answer:\n",
    "            if index == queries[i]:\n",
    "                score.append(1)\n",
    "                break\n",
    "        if len(score) != i + 1:\n",
    "            score.append(0)\n",
    "    return sum(score) / len(score) if len(score) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a95645b1-c445-4f09-a601-6692fe1e1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_models = ['cross-encoder/ms-marco-MiniLM-L-12-v2',\n",
    "                'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "                'cross-encoder/ms-marco-MiniLM-L-4-v2',\n",
    "                'cross-encoder/ms-marco-MiniLM-L-2-v2',\n",
    "                'cross-encoder/ms-marco-TinyBERT-L-6',\n",
    "                'cross-encoder/ms-marco-TinyBERT-L-2-v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd8636ca-4169-4880-b3b9-3819d32225a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17552</td>\n",
       "      <td>Who is the author of the memoir \"Nicotine\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17382</td>\n",
       "      <td>What skills are inmates learning in the innova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17547</td>\n",
       "      <td>Who surrendered to the authorities for changin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17778</td>\n",
       "      <td>What is the name of the journalist and archivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17841</td>\n",
       "      <td>Which leader of the fringe movement embracing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18228</td>\n",
       "      <td>Who narrated the documentary \"I Am Not Your Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18443</td>\n",
       "      <td>Who is the billionaire restaurant owner nomina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18170</td>\n",
       "      <td>Who is the federal judge that ordered Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17980</td>\n",
       "      <td>What business relationship between Donald Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17838</td>\n",
       "      <td>Who vowed to take executive action on a nearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17544</td>\n",
       "      <td>What was Hubert Edward Spires's discharge stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17434</td>\n",
       "      <td>What advice was given to Mr. LaCasse regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17972</td>\n",
       "      <td>What word did The New York Times ultimately ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18163</td>\n",
       "      <td>What is the title of Vladimir Nabokov's contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17292</td>\n",
       "      <td>What adversity have the Mu'iz family faced?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17645</td>\n",
       "      <td>Why did Jennifer Holliday decide to withdraw f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17556</td>\n",
       "      <td>What did Donald Trump concede for the first ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18382</td>\n",
       "      <td>Who founded Airline Ambassadors International?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17701</td>\n",
       "      <td>Where was the suspect in the Istanbul nightclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18084</td>\n",
       "      <td>What significant event involving Emmett Till o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17372</td>\n",
       "      <td>Who recently sold his personal papers to the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18054</td>\n",
       "      <td>Who was Don Ciccone, and what significant role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18352</td>\n",
       "      <td>Who is celebrating their sapphire jubilee, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17787</td>\n",
       "      <td>Who performed a soulful rendition of 'America ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17765</td>\n",
       "      <td>Who challenged Germany's national atonement fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17502</td>\n",
       "      <td>What trend did Jerry Silverman, the president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17500</td>\n",
       "      <td>What significant event in Tom Casperson's poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18174</td>\n",
       "      <td>Who has been involved in financial mismanageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18130</td>\n",
       "      <td>Who won the Australian Open for the fifth time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18282</td>\n",
       "      <td>What significant event occurred in Greenwood, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17629</td>\n",
       "      <td>Who announced their resignation from Sony's en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17507</td>\n",
       "      <td>What was the incident involving a Palestinian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17406</td>\n",
       "      <td>How many people did Governor Peter Shumlin of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17863</td>\n",
       "      <td>Who attended the Women's March on Washington?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17990</td>\n",
       "      <td>What was the outcome of the 1998 Australian Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18122</td>\n",
       "      <td>What role did Steve Bannon receive in the Nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17837</td>\n",
       "      <td>What did President Trump emphasize in his Inau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                           question\n",
       "0    17552        Who is the author of the memoir \"Nicotine\"?\n",
       "1    17382  What skills are inmates learning in the innova...\n",
       "2    17547  Who surrendered to the authorities for changin...\n",
       "3    17778  What is the name of the journalist and archivi...\n",
       "4    17841  Which leader of the fringe movement embracing ...\n",
       "5    18228  Who narrated the documentary \"I Am Not Your Ne...\n",
       "6    18443  Who is the billionaire restaurant owner nomina...\n",
       "7    18170  Who is the federal judge that ordered Presiden...\n",
       "8    17980  What business relationship between Donald Trum...\n",
       "9    17838  Who vowed to take executive action on a nearly...\n",
       "10   17544  What was Hubert Edward Spires's discharge stat...\n",
       "11   17434  What advice was given to Mr. LaCasse regarding...\n",
       "12   17972  What word did The New York Times ultimately ch...\n",
       "13   18163  What is the title of Vladimir Nabokov's contro...\n",
       "14   17292        What adversity have the Mu'iz family faced?\n",
       "15   17645  Why did Jennifer Holliday decide to withdraw f...\n",
       "16   17556  What did Donald Trump concede for the first ti...\n",
       "17   18382     Who founded Airline Ambassadors International?\n",
       "18   17701  Where was the suspect in the Istanbul nightclu...\n",
       "19   18084  What significant event involving Emmett Till o...\n",
       "20   17372  Who recently sold his personal papers to the B...\n",
       "21   18054  Who was Don Ciccone, and what significant role...\n",
       "22   18352  Who is celebrating their sapphire jubilee, mar...\n",
       "23   17787  Who performed a soulful rendition of 'America ...\n",
       "24   17765  Who challenged Germany's national atonement fo...\n",
       "25   17502  What trend did Jerry Silverman, the president ...\n",
       "26   17500  What significant event in Tom Casperson's poli...\n",
       "27   18174  Who has been involved in financial mismanageme...\n",
       "28   18130  Who won the Australian Open for the fifth time...\n",
       "29   18282  What significant event occurred in Greenwood, ...\n",
       "30   17629  Who announced their resignation from Sony's en...\n",
       "31   17507  What was the incident involving a Palestinian ...\n",
       "32   17406  How many people did Governor Peter Shumlin of ...\n",
       "33   17863      Who attended the Women's March on Washington?\n",
       "34   17990  What was the outcome of the 1998 Australian Op...\n",
       "35   18122  What role did Steve Bannon receive in the Nati...\n",
       "36   17837  What did President Trump emphasize in his Inau..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list = pd.read_csv('question_test_data_2.csv')\n",
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "baf0474b-4e34-412a-aaec-5c05e3635604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(question_list, cross_model):\n",
    "    start_time = time.time()\n",
    "\n",
    "    answers = []\n",
    "    for id, question in enumerate(question_list['question']):\n",
    "        answer = query_answer(question, id, cross_model)\n",
    "        answers.append(answer)\n",
    "\n",
    "    answers = [answer for sublist in answers for answer in sublist]\n",
    "    answers = pd.DataFrame(answers)\n",
    "    \n",
    "    question_article_ids = {}\n",
    "    for i, question_id in enumerate(answers['question_id']):\n",
    "        if question_id not in question_article_ids:\n",
    "            question_article_ids[question_id] = [answers['id'][i]]\n",
    "        else:\n",
    "            question_article_ids[question_id].append(answers['id'][i])\n",
    "\n",
    "    reranked_result = [question_article_ids[x] for x in question_article_ids]\n",
    "\n",
    "    accuracy = accuracy_score(reranked_result, question_list['doc_id'])\n",
    "    mrr = mrr_score(reranked_result, question_list['doc_id'])\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    result = {'accuracy_score': accuracy, \n",
    "              'mrr_score': mrr,\n",
    "              'time': elapsed_time}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9266dc6a-f705-4d26-a134-d596814bc6a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "query_answer() missing 1 required positional argument: 'cross_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cross_model_name \u001b[38;5;129;01min\u001b[39;00m cross_models:\n\u001b[0;32m      4\u001b[0m     cross_model \u001b[38;5;241m=\u001b[39m CrossEncoder(cross_model_name) \n\u001b[1;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m test_model(question_list, cross_model)\n\u001b[0;32m      8\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cross_model_name\n\u001b[0;32m     10\u001b[0m     test_result\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[81], line 6\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(question_list, cross_model)\u001b[0m\n\u001b[0;32m      4\u001b[0m answers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, question \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(question_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m----> 6\u001b[0m     answer \u001b[38;5;241m=\u001b[39m query_answer(question, \u001b[38;5;28mid\u001b[39m, cross_model)\n\u001b[0;32m      7\u001b[0m     answers\u001b[38;5;241m.\u001b[39mappend(answer)\n\u001b[0;32m      9\u001b[0m answers \u001b[38;5;241m=\u001b[39m [answer \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m answers \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "\u001b[1;31mTypeError\u001b[0m: query_answer() missing 1 required positional argument: 'cross_model'"
     ]
    }
   ],
   "source": [
    "test_result = []\n",
    "\n",
    "for cross_model_name in cross_models:\n",
    "    cross_model = CrossEncoder(cross_model_name) \n",
    "\n",
    "    result = test_model(question_list, cross_model)\n",
    "\n",
    "    result['cross_model'] = cross_model_name\n",
    "    \n",
    "    test_result.append(result)\n",
    "\n",
    "test_result = pd.DataFrame(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "488779e1-76c9-45c7-b540-50dbc32ecf64",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_result\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmrr_score\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "test_result.sort_values(by='mrr_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbbed6-f57f-4686-891e-f2b9d6466935",
   "metadata": {},
   "source": [
    "### 1.3 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3cbdd10-9be1-435f-8137-cce5978647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import _pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc734f9-938a-4595-a93f-eadc9da3b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb3b7115-d629-4729-acbe-973d6321dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\a1881044\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\a1881044\\.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecdd3b5b-e4a2-491b-ada1-abb02836d841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "673222fc-34b3-444b-99e8-4ee441f73e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text, truncation=True, max_length=512)\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example through the model.\n",
    "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
    "                    return_dict=True) \n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ae7a743-2ab7-4cb2-9141-25f7912c294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARIS Islamic State driven ancient city Palmyra March, Yves Ubelmann got call\n",
      "Syria's director antiquity come hurry. architect training, Mr. Ubelmann, 36,\n",
      "worked Syria country engulfed war. special urgency kind work youthful team\n",
      "architects, mathematician designer cramped office Paris: producing digital copy\n",
      "threatened historical sites. Palmyra, part already destroyed Islamists deemed\n",
      "monument idolatrous, still rigged explosives. Houmam Saad, Syrian colleague,\n",
      "spent four day flying drone robot camera crumbled arch temples. Drones four six\n",
      "rotor hover really close register structural details, every crack hole, take\n",
      "precise measurements, said Mr. Ubelmann, founded company Iconem. stuff architect\n",
      "archaeologist need. need new push virtual preservation scientists, archaeologist\n",
      "others, like Mr. Ubelmann, compiling large scale. record could used create\n",
      "computer model would show monument endangered historical site might one day\n",
      "restored, repaired reconstructed. special interest today ancient site Syria,\n",
      "also Iraq, suffered war, looting Islamic State. Palmyra difficult, Mr. Ubelmann\n",
      "said. terrorist uploading video blowing monument smashing statue manipulate\n",
      "public opinion, said. felt best response magnify picture place show splendor\n",
      "importance culture. became war images. latest front war exhibition hall Grand\n",
      "Palais Paris, where, Jan. 9, many 40, 000 image team took Palmyra become basis\n",
      "displays. Called Eternal Sites: Bamiyan Palmyra, show aim draw attention rising\n",
      "threat global heritage. underscore exhibition's political importance, opened\n",
      "several week ago President Fran'ois Hollande France, described act resistance?\n",
      "terror intolerance. Showing beauty Middle Eastern heritage, said, best answer\n",
      "Islamist propaganda hate, destruction death. Martinez, director Louvre lead\n",
      "curator show, said site chosen threat pillaging, neglect destruction accessible\n",
      "public. said aimed mobilize public opinion face devastation unique heritage.\n",
      "Besides image Palmyra, multimedia show project enormous photograph videos,\n",
      "immersing visitor different eras, including ancient Iraqi city Khorsabad around\n",
      "700 B. C. mosque Damascus medieval Christian citadel. Mr. Ubelmann dismissed\n",
      "criticism collaboration government Syrian president, Bashar . working pro bono,\n",
      "government, help archaeologists, said. shared work Syrian archaeologists, said,\n",
      "adding, also train colleague later own. paramount memory potential restoration.\n",
      "last year, team flown drone 20 historic site Syria. Recently, moved zone Iraq,\n",
      "close front line fight Islamic State. team analyzing war's effect remains\n",
      "thriving city dating back 3, 000 years, including Nineveh, Khorsabad thrashed\n",
      "temple palace Nimrud, government drove jihadist November. 2015, Islamists sent\n",
      "video showing militant using sledgehammer break relief human figure mythical\n",
      "winged bull part campaign. Nimrud probably splendid Assyrian cities, Layla\n",
      "Abdulkarim, Syrian architect, said analyzed aerial photographs. Using drone\n",
      "archaeological work entirely new, specialist say, recent gathering Paris\n",
      "researcher Europe Middle East said practice war archaeology, is, collecting\n",
      "reliable data areas. image drone war zone proved immensely valuable. barely\n",
      "scratching surface. war, close 150 archaeological project underway, Syria,\n",
      "researcher said. Experts many country trying ass damage Syria's old city also\n",
      "area Islamic State held sway straddling Iraq Syria, region seen central human\n",
      "history often called birthplace modern economics writing. outcry data havoc\n",
      "wreaked Yemen Saudi bombing. People exchanging satellite image data blog\n",
      "research platforms, real assessment yet many ancient site accessible, said\n",
      "Pascal Butterlin, professor archaeology Sorbonne Paris. Time essence, even case\n",
      "ruins, Mr. Butterlin said. led expedition 20 year Mari, near Syria's border\n",
      "Iraq. fleeing, guard Mari reported looter come Iraq, said. need know place need\n",
      "stabilized looter altered sites, said. Important evidence, like clandestine\n",
      "pits, disappear quickly sandstorm erosion. Cheikhmous Ali, Syrian archaeologist\n",
      "based France, founded international group Association Protection Syrian\n",
      "Archaeology, said report organized pillaging continued. first wave looting began\n",
      "2012, Mr. Ali said, looting accelerated since 2014 arrival Islamic State.\n",
      "jihadist motivated destroy artifacts, also allowed looter operate exchange\n",
      "money. Mr. Ali said kept ever changing tally museum bombed, object carted off,\n",
      "safe stolen. exhibition Paris, drawing large crowds, coincides History Begins\n",
      "Mesopotamia, show Louvre's regional museum Lens. exhibition highlight French\n",
      "government's active concern cultural damage Syria, briefly controlled France\n",
      "first half 20th century. Mr. Hollande taken strong interest, condemning\n",
      "deliberate destruction patrimony side war crimes. past month, France offered $30\n",
      "million toward proposed $100 million fund protect site fighting abates, provide\n",
      "emergency storage artifact eventually rehabilitate monuments. Eternal Sites?\n",
      "opening Grand Palais, Mr. Hollande stressed France taking Syrian refugee trying\n",
      "protect monument great historical cultural importance mean ignoring suffering\n",
      "population. concerned patrimony? asked. important, saving life saving stones?\n",
      "reality, two inseparable.\n",
      "5215\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Wrap text to 80 characters.\n",
    "wrapper = textwrap.TextWrapper(width=80) \n",
    "\n",
    "answer_text = news_dataset['processed_article'].iloc[0]\n",
    "\n",
    "\n",
    "print(wrapper.fill(answer_text))\n",
    "print(len(answer_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37e20b2b-623b-4ae9-9a62-10b7a1478f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 512 tokens.\n",
      "\n",
      "Answer: \"team\"\n"
     ]
    }
   ],
   "source": [
    "question = \"What motivated Yves Ubelmann and his team to urgently document threatened historical sites like Palmyra, and what methods did they employ?\"\n",
    "answer_question(question, answer_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
