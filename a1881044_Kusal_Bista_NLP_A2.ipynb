{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {
    "id": "6730fecf"
   },
   "source": [
    "# Assignment 2\n",
    "### Kusal Bista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb617560-ebfe-47a0-a5ee-fb6a0ec56589",
   "metadata": {
    "id": "fb617560-ebfe-47a0-a5ee-fb6a0ec56589"
   },
   "outputs": [],
   "source": [
    "# Libraries for data reading\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import neuralcoref\n",
    "# import stanza\n",
    "# Libraries for pre-processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Libraries for information retrieval\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Libraries for data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Libraries for question answering\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import time\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858f5298-3839-41d9-a86d-2947fc751b10",
   "metadata": {
    "id": "858f5298-3839-41d9-a86d-2947fc751b10"
   },
   "outputs": [],
   "source": [
    "# !pip install tabulate\n",
    "# !pip install matplotlib\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8771dd7c",
   "metadata": {
    "id": "8771dd7c"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cde6e7-8e19-4357-8ade-60114da4174c",
   "metadata": {
    "id": "20cde6e7-8e19-4357-8ade-60114da4174c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install tabulate\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0d6e5f-384d-47c7-b959-51604a6bc35c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d0d6e5f-384d-47c7-b959-51604a6bc35c",
    "outputId": "b4afad1b-2ea2-4bf7-ac39-4490af124577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/poojakc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/poojakc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/poojakc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/poojakc/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a509-a9f1-405e-8d0b-6dc96e679322",
   "metadata": {
    "id": "6fd8a509-a9f1-405e-8d0b-6dc96e679322"
   },
   "source": [
    "### 1 Reading dataset and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1474a82-79ad-4c8d-8bae-e4d4056d2860",
   "metadata": {
    "id": "c1474a82-79ad-4c8d-8bae-e4d4056d2860"
   },
   "outputs": [],
   "source": [
    "news_dataset = pd.read_csv('news_dataset.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de28f0fb-9811-4b2d-96f4-63ff46825a35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "de28f0fb-9811-4b2d-96f4-63ff46825a35",
    "outputId": "a4aa6b9c-c11a-4fdd-cec9-398bf2738cfd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>Marlise Simons</td>\n",
       "      <td>1/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>architecture</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Andy Newman</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>art</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Emma G. Fitzsimmons</td>\n",
       "      <td>2/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>3/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>Jim Rutenberg</td>\n",
       "      <td>5/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               author        date  year month         topic  \\\n",
       "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
       "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
       "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
       "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
       "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
       "\n",
       "                                             article  \n",
       "0  PARIS  ?   When the Islamic State was about to...  \n",
       "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
       "2  Finally. The Second Avenue subway opened in Ne...  \n",
       "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
       "4  For Megyn Kelly, the shift from Fox News to NB...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04327fa-2d19-4ba8-9291-984303ca5ef8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e04327fa-2d19-4ba8-9291-984303ca5ef8",
    "outputId": "6f935422-9a93-4eba-e846-527c0ce8a585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset shape: (100, 7)\n"
     ]
    }
   ],
   "source": [
    "# selecting 100 sample\n",
    "test_article = news_dataset[news_dataset['id'] == 17574]\n",
    "sample_size = 100\n",
    "if news_dataset.shape[0] >= sample_size:\n",
    "    news_dataset = news_dataset.sample(n=sample_size, random_state=42)  # Adjusting random_state for reproducibility\n",
    "    news_dataset.reset_index(drop=True, inplace=True)\n",
    "    print(\"Sampled dataset shape:\", news_dataset.shape)\n",
    "else:\n",
    "    print(\"Dataset size is less than the sample size. Cannot perform sampling.\")\n",
    "\n",
    "news_dataset = pd.concat([news_dataset, test_article], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573c3a0c-0f0f-4790-a794-9a0f87613737",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "573c3a0c-0f0f-4790-a794-9a0f87613737",
    "outputId": "f96cb50c-7224-4194-92ad-222915f604eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       101 non-null    int64 \n",
      " 1   author   100 non-null    object\n",
      " 2   date     101 non-null    object\n",
      " 3   year     101 non-null    object\n",
      " 4   month    101 non-null    object\n",
      " 5   topic    101 non-null    object\n",
      " 6   article  101 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "news_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177652d-42ca-4e6f-ba8d-ad3a95c503b1",
   "metadata": {
    "id": "b177652d-42ca-4e6f-ba8d-ad3a95c503b1"
   },
   "source": [
    "### 1.2 Handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0eccc9-7ea3-4155-be46-4373e2338b56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be0eccc9-7ea3-4155-be46-4373e2338b56",
    "outputId": "40e461b7-f45f-4291-cc3e-ed59840e1c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value\n",
      "id         0\n",
      "author     1\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf22242e-51d4-48a3-b91d-58d55ca2216a",
   "metadata": {
    "id": "bf22242e-51d4-48a3-b91d-58d55ca2216a"
   },
   "outputs": [],
   "source": [
    "# Handling missing value\n",
    "news_dataset['author'] = news_dataset['author'].fillna('No author')\n",
    "# checking missing value after handling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e52309-3c2c-4899-b621-263597321d8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71e52309-3c2c-4899-b621-263597321d8a",
    "outputId": "27825a7f-2ce9-4a51-869b-682425d0e0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After handling missing value\n",
      "id         0\n",
      "author     0\n",
      "date       0\n",
      "year       0\n",
      "month      0\n",
      "topic      0\n",
      "article    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"After handling missing value\")\n",
    "print(news_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb4773a-7d99-41fe-bed4-f10628d76eb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "edb4773a-7d99-41fe-bed4-f10628d76eb1",
    "outputId": "2c007dcf-0104-4e3e-bd1d-3fae1ce16b1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17904</td>\n",
       "      <td>Brooks Barnes</td>\n",
       "      <td>23/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Nominations for the 89th Academy Awards will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18166</td>\n",
       "      <td>Matt Flegenheimer</td>\n",
       "      <td>2/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   President Trump, seeming to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18169</td>\n",
       "      <td>Somini Sengupta</td>\n",
       "      <td>2/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>UNITED NATIONS  ?   The new secretary general ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18055</td>\n",
       "      <td>Emily Palmer</td>\n",
       "      <td>26/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>On a chilly October morning, Talea Childs, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17776</td>\n",
       "      <td>Liam Stack</td>\n",
       "      <td>20/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>celebrities may be staying away from Donald J....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18079</td>\n",
       "      <td>Dave Philipps</td>\n",
       "      <td>5/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>science</td>\n",
       "      <td>RICHLAND, Wash.  ?   When Tim Snider arrived o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18019</td>\n",
       "      <td>Justin Wolfers</td>\n",
       "      <td>30/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>Even if President Trump?s      fails over the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17895</td>\n",
       "      <td>Adam Liptak</td>\n",
       "      <td>24/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>WASHINGTON  ?   The Supreme Court rejected on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18308</td>\n",
       "      <td>Ken Belson</td>\n",
       "      <td>8/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>sports</td>\n",
       "      <td>HOUSTON  ?   There was the game on the field, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17452</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>8/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>HOUSTON  ?   Follow our live N. F. L. playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18253</td>\n",
       "      <td>Shivani Vora</td>\n",
       "      <td>14/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Beach and spa vacations are typically associat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17382</td>\n",
       "      <td>Gaia Pianigiani</td>\n",
       "      <td>25/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>LECCE, Italy  ?   One of his first students wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                author        date  year month          topic  \\\n",
       "0   17904         Brooks Barnes  23/01/2017  2017     1  entertainment   \n",
       "1   18166     Matt Flegenheimer   2/02/2017  2017     2       business   \n",
       "2   18169       Somini Sengupta   2/02/2017  2017     2       business   \n",
       "3   18055          Emily Palmer  26/01/2017  2017     1      lifestyle   \n",
       "4   17776            Liam Stack  20/01/2017  2017     1  entertainment   \n",
       "5   18079         Dave Philipps   5/02/2017  2017     2        science   \n",
       "6   18019        Justin Wolfers  30/01/2017  2017     1       politics   \n",
       "7   17895           Adam Liptak  24/01/2017  2017     1       politics   \n",
       "8   18308            Ken Belson   8/02/2017  2017     2         sports   \n",
       "9   17452  The Associated Press   8/01/2017  2017     1         sports   \n",
       "10  18253          Shivani Vora  14/02/2017  2017     2  entertainment   \n",
       "11  17382       Gaia Pianigiani  25/01/2017  2017     1       business   \n",
       "\n",
       "                                              article  \n",
       "0   Nominations for the 89th Academy Awards will b...  \n",
       "1   WASHINGTON  ?   President Trump, seeming to re...  \n",
       "2   UNITED NATIONS  ?   The new secretary general ...  \n",
       "3   On a chilly October morning, Talea Childs, 4, ...  \n",
       "4   celebrities may be staying away from Donald J....  \n",
       "5   RICHLAND, Wash.  ?   When Tim Snider arrived o...  \n",
       "6   Even if President Trump?s      fails over the ...  \n",
       "7   WASHINGTON  ?   The Supreme Court rejected on ...  \n",
       "8   HOUSTON  ?   There was the game on the field, ...  \n",
       "9   HOUSTON  ?   Follow our live N. F. L. playoffs...  \n",
       "10  Beach and spa vacations are typically associat...  \n",
       "11  LECCE, Italy  ?   One of his first students wa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset = news_dataset.drop_duplicates(subset=['article'], keep='first').reset_index(drop=True)\n",
    "news_dataset.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbbed6-f57f-4686-891e-f2b9d6466935",
   "metadata": {
    "id": "2dcbbed6-f57f-4686-891e-f2b9d6466935"
   },
   "source": [
    "### 1.3 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e2c0aee-9743-46fc-8810-c8072892a0b5",
   "metadata": {
    "id": "2e2c0aee-9743-46fc-8810-c8072892a0b5"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "\n",
    "def pre_process(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update([\"This\", \"The\", \"the\"])\n",
    "    s = \" \\[(?=.*\\d).*?\\]\"\n",
    "    # Lemmatization and removal of stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     print(data)\n",
    "    result = []\n",
    "    for text in data:\n",
    "        doc = nlp(text)\n",
    "        # Clean text\n",
    "        # Remove non-ASCII characters\n",
    "        text = ''.join([char for char in text if ord(char) < 128])\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove question mark problems\n",
    "        text = re.sub(r'(\\s\\?)',' ',text)\n",
    "        text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "        text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "        text = re.sub(r\"\\?+\", \"?\", text)\n",
    "        text = text.strip()\n",
    "        # Lemmatization and removal of stopwords\n",
    "        processed_text = \" \".join([lemmatizer.lemmatize(word) for word in re.sub(s, \"\", text).split() if word.lower() not in stop_words])\n",
    "        result.append(processed_text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d773dd50-b4ea-441c-97ea-d077c2a98e33",
   "metadata": {
    "id": "d773dd50-b4ea-441c-97ea-d077c2a98e33"
   },
   "outputs": [],
   "source": [
    "news_dataset['processed_article'] = pre_process(news_dataset['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "820cfb36-4b63-4def-be79-4844cbec48a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "820cfb36-4b63-4def-be79-4844cbec48a6",
    "outputId": "a43606ec-2247-4e6a-a4e8-e40d4f5f9774"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17904</td>\n",
       "      <td>Brooks Barnes</td>\n",
       "      <td>23/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Nominations for the 89th Academy Awards will b...</td>\n",
       "      <td>Nominations 89th Academy Awards announced Tues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18166</td>\n",
       "      <td>Matt Flegenheimer</td>\n",
       "      <td>2/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>WASHINGTON  ?   President Trump, seeming to re...</td>\n",
       "      <td>WASHINGTON President Trump, seeming relish fig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18169</td>\n",
       "      <td>Somini Sengupta</td>\n",
       "      <td>2/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>UNITED NATIONS  ?   The new secretary general ...</td>\n",
       "      <td>UNITED NATIONS new secretary general United Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18055</td>\n",
       "      <td>Emily Palmer</td>\n",
       "      <td>26/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>On a chilly October morning, Talea Childs, 4, ...</td>\n",
       "      <td>chilly October morning, Talea Childs, 4, still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17776</td>\n",
       "      <td>Liam Stack</td>\n",
       "      <td>20/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>celebrities may be staying away from Donald J....</td>\n",
       "      <td>celebrity may staying away Donald J. Trump's i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             author        date  year month          topic  \\\n",
       "0  17904      Brooks Barnes  23/01/2017  2017     1  entertainment   \n",
       "1  18166  Matt Flegenheimer   2/02/2017  2017     2       business   \n",
       "2  18169    Somini Sengupta   2/02/2017  2017     2       business   \n",
       "3  18055       Emily Palmer  26/01/2017  2017     1      lifestyle   \n",
       "4  17776         Liam Stack  20/01/2017  2017     1  entertainment   \n",
       "\n",
       "                                             article  \\\n",
       "0  Nominations for the 89th Academy Awards will b...   \n",
       "1  WASHINGTON  ?   President Trump, seeming to re...   \n",
       "2  UNITED NATIONS  ?   The new secretary general ...   \n",
       "3  On a chilly October morning, Talea Childs, 4, ...   \n",
       "4  celebrities may be staying away from Donald J....   \n",
       "\n",
       "                                   processed_article  \n",
       "0  Nominations 89th Academy Awards announced Tues...  \n",
       "1  WASHINGTON President Trump, seeming relish fig...  \n",
       "2  UNITED NATIONS new secretary general United Na...  \n",
       "3  chilly October morning, Talea Childs, 4, still...  \n",
       "4  celebrity may staying away Donald J. Trump's i...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a041b-82b8-4302-908a-45d6bc6b4774",
   "metadata": {
    "id": "173a041b-82b8-4302-908a-45d6bc6b4774"
   },
   "source": [
    "#### 2 Classical retrivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcb4141-bd9c-476b-9b6b-0c392fb41dc3",
   "metadata": {
    "id": "2bcb4141-bd9c-476b-9b6b-0c392fb41dc3"
   },
   "outputs": [],
   "source": [
    "#Mishra, A., & Vishwakarma, S. (2015)\n",
    "\n",
    "nlp_md = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "class TextMatchingUtility:\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset  # Dataset\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        \n",
    "    def extract_entities(articles):\n",
    "        doc = nlp(articles)\n",
    "        entities = []\n",
    "        for ent in doc.ents:\n",
    "            entities.append((ent.text, ent.label_))\n",
    "        return entities\n",
    "\n",
    "    def preprocess_query(self, query):\n",
    "        # Regular expression to match text patterns\n",
    "        s = \" \\[(?=.*\\d).*?\\]\"\n",
    "        # Removing stopwords and Lemmatization\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words.extend([\"This\", \"The\", \"the\"])\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        result = [\" \".join([lemmatizer.lemmatize(word) for word in re.sub(s, \"\", query).split() if word not in stop_words])]\n",
    "        return result\n",
    "\n",
    "\n",
    "    def tf_idf_score(self, query, articles):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        # Convert to word vector\n",
    "        articles_wv = vectorizer.fit_transform(articles)\n",
    "        # Convert to word vector\n",
    "        query_wv = vectorizer.transform([query])\n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(query_wv, articles_wv)[0]\n",
    "        return similarities\n",
    "\n",
    "    def spacy_score(self, query, articles):\n",
    "        # Convert to word vector\n",
    "        query_nlp = nlp_md(str(query))\n",
    "        # Convert to word vector\n",
    "        articles_nlp = [nlp_md(article) for article in articles]\n",
    "        # Calculate similarity\n",
    "        similarities = [query_nlp.similarity(article_nlp) for article_nlp in articles_nlp]\n",
    "        return similarities\n",
    "\n",
    "    def get_best_sentences(self, query, article_id, word_vector, top_n=4):\n",
    "        article = self.data.loc[self.data['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        # Convert text into sentences\n",
    "        sentences_clean = tokenize.sent_tokenize(article)\n",
    "        # Calculate similarity\n",
    "        if word_vector == \"tf-idf\":\n",
    "            similarities = self.tf_idf_score(query, sentences_clean)\n",
    "        elif word_vector == \"spaCy\":\n",
    "            similarities = self.spacy_score(query, sentences_clean)\n",
    "        # Get the indices of top N scores\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "        # Get the top N sentences and their scores\n",
    "        top_sentences = [(sentences_clean[i], similarities[i]) for i in top_indices]\n",
    "        sentences = [sentence[0] for sentence in top_sentences]\n",
    "        # Coreference resolution for each sentence\n",
    "        resolved_sentences = []\n",
    "        for sentence in sentences:\n",
    "            doc = nlp(sentence)\n",
    "            resolved_sentences.append(doc._.coref_resolved)\n",
    "        resolved_top_sentences = [(resolved_sentences[i], similarity) for i, (_, similarity) in enumerate(top_sentences)]\n",
    "        return resolved_top_sentences\n",
    "\n",
    "    def get_best_sentence(self, query, article_id, word_vector):\n",
    "        article = self.data.loc[self.data['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        # Convert text into sentences\n",
    "        sentences_clean = tokenize.sent_tokenize(article)\n",
    "        # Calculate similarity\n",
    "        if word_vector == \"tf-idf\":\n",
    "            similarities = self.tf_idf_score(query, sentences_clean)\n",
    "        elif word_vector == \"spaCy\":\n",
    "            similarities = self.spacy_score(query, sentences_clean)\n",
    "\n",
    "        # Get the maximum score index position\n",
    "        best_idx = np.array(similarities).argmax()\n",
    "        # Get the best score\n",
    "        best_score = max(similarities)\n",
    "        # Get original data\n",
    "        for j in range(len(self.data['id'])):\n",
    "            if self.data['id'][j] == article_id:\n",
    "                topic = self.data['article'][j]\n",
    "        sentences_topic = tokenize.sent_tokenize(topic)\n",
    "        answer = sentences_topic[best_idx]\n",
    "        doc = nlp(answer)\n",
    "        print(\"Article ID \", article_id)\n",
    "        print(\"Question:\", query)\n",
    "        if best_score < 0.3:\n",
    "            print(\"No answer found\")\n",
    "        else:\n",
    "            print(\"Answer:\",doc._.coref_resolved)\n",
    "            print(\"Score\", best_score,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cbb60-87e5-4a14-9d21-b3878e6f58bf",
   "metadata": {
    "id": "180cbb60-87e5-4a14-9d21-b3878e6f58bf"
   },
   "source": [
    "### 2.1 tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a6d3ac-7791-4227-8f55-5b7d496fc184",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9a6d3ac-7791-4227-8f55-5b7d496fc184",
    "outputId": "31d3718a-c486-4cd4-fb67-478178393b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer 1: de facto leader, Jay Y. Lee, vice chairman Samsung, questioned Thursday, according special prosecutor's office, recommended also investigated suspicion perjury.\n",
      "Score: 0.36449756195127636\n",
      "\n",
      "Answer 2: Mr. Lee effectively run Samsung, South Korea's largest conglomerate son chairman, Mr. Lee incapacitated health problems.\n",
      "Score: 0.1805434411681926\n",
      "\n",
      "Answer 3: Moon chairman pension fund, arrested last month charge illegally pressured fund back merger South Korea's health welfare minister.\n",
      "Score: 0.12484468335180934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Sample question\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id = 17574\n",
    "word_vector = 'tf-idf'\n",
    "\n",
    "top_results = tm_utility.get_best_sentences(question, article_id, word_vector, top_n=3)\n",
    "# top_results = tm_utility.get_best_sentence(question, article_id, word_vector)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "for i, (answer, score) in enumerate(top_results, 1):\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print(\"Score:\", score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e91057-d03f-464c-b23d-7644b688913a",
   "metadata": {
    "id": "11e91057-d03f-464c-b23d-7644b688913a"
   },
   "source": [
    "### 2.2 spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f99598df-8b99-466c-83cc-95a86618fdde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99598df-8b99-466c-83cc-95a86618fdde",
    "outputId": "c7255f50-8701-420d-a139-2d1e20e8de10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer 1: expected asked whether donation Samsung made two foundation controlled Choi longtime friend president, amounted bribes, role, any, played decision give money.\n",
      "Score: 0.8360479012668263\n",
      "\n",
      "Answer 2: special prosecutor's office said evidence Mr. Lee received request bribery president ordered Samsung subsidiary send bribe destination designated president.\n",
      "Score: 0.834839036010658\n",
      "\n",
      "Answer 3: Also Wednesday, special prosecutor's office said acquired tablet computer used Ms. Choi contained email exchanged Samsung executive.\n",
      "Score: 0.8122892019843948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Sample question\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id = 17574\n",
    "word_vector = 'spaCy'\n",
    "\n",
    "top_results = tm_utility.get_best_sentences(question, article_id, word_vector, top_n=3)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "for i, (answer, score) in enumerate(top_results, 1):\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print(\"Score:\", score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8c3bc-ae47-418c-9cf8-ce3a9b4c548d",
   "metadata": {
    "id": "9fa8c3bc-ae47-418c-9cf8-ce3a9b4c548d"
   },
   "source": [
    "### Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f811a17c-cfd6-4a31-8af1-c0debaf1b335",
   "metadata": {
    "id": "f811a17c-cfd6-4a31-8af1-c0debaf1b335"
   },
   "outputs": [],
   "source": [
    " # Test questions in one passage\n",
    "test_questions = [\n",
    "    {'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'Who is the de facto head of Samsung being questioned for bribery?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'What scandal led to President Park\\'s impeachment?', 'answer': 'corruption scandal'},\n",
    "    {'query': 'What is the name of Samsung\\'s vice chairman?', 'answer': 'Jay Y. Lee'},\n",
    "    {'query': 'What is the name of the special prosecutor investigating the corruption scandal?', 'answer': '[SEP]'},\n",
    "    {'query': 'Who is on trial at the Constitutional Court?', 'answer': 'Ms. Park'},\n",
    "    {'query': 'What is the name of the special prosecutor\\'s office spokesman?', 'answer': 'Lee'},\n",
    "    {'query': 'What charges were filed against Ms. Choi by state prosecutors?', 'answer': 'coercing 53 big businesses'},\n",
    "    {'query': 'What organization\\'s support was crucial for the merger of two Samsung affiliates?', 'answer': 'National Pension Service'},\n",
    "    {'query': 'What amount did Samsung contribute to Ms. Choi\\'s winter sports program?', 'answer': '$1.3 million'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Jz1ShgMhDMYz",
   "metadata": {
    "id": "Jz1ShgMhDMYz"
   },
   "outputs": [],
   "source": [
    "test_questions_all = [\n",
    "    {'query': 'What movie is seen as a leading contender for Best Picture at the 89th Academy Awards?', 'answer': 'Moonlight', 'passage_id': 17904},  # article = 17904\n",
    "    {'query': 'Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?', 'answer': 'Mitch McConnell', 'passage_id': 18166},  # article 18166\n",
    "    {'query': 'What tactic did President Trump suggest Senate Majority Leader Mitch McConnell use to confirm Neil Gorsuch to the Supreme Court?', 'answer': 'Nuclear option', 'passage_id': 18166},  # article 18166\n",
    "    {'query': \"What is the name of Talea's mother?\", 'answer': 'Trenicia', 'passage_id': 18055},  # 18055\n",
    "    {'query': 'Who is the Roman Catholic Archbishop of New York?', 'answer': 'Cardinal Dolan', 'passage_id': 17776},  # article 17776\n",
    "    {'query': \"How many religious leaders are scheduled to participate in Donald J. Trump's inauguration ceremony?\", 'answer': 'Six', 'passage_id': 17776},  # 17776\n",
    "    {'query': 'What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?', 'answer': 'Enewetak Atoll', 'passage_id': 18079},  # 18079\n",
    "    {'query': \"What is the biggest problem identified by Energy Department reports regarding the cleanup of Enewetak Atoll?\", 'answer': 'Runit Island', 'passage_id': 17895},  # 17895\n",
    "    {'query': 'According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?', 'answer': 'Choose smaller cities', 'passage_id': 18253},  # 18253\n",
    "    {'query': 'What amount did Samsung contribute to Ms. Choi\\'s winter sports program?', 'answer': '$1.3 million', 'passage_id': 17574}  # 17574\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ba4fc0-1ba8-48a1-b172-20381d0b1762",
   "metadata": {
    "id": "95ba4fc0-1ba8-48a1-b172-20381d0b1762"
   },
   "outputs": [],
   "source": [
    "class TestUtility:\n",
    "    def __init__(self, text_matching_utility, test_questions):\n",
    "        self.text_matching_utility = text_matching_utility\n",
    "        self.test_questions = test_questions\n",
    "\n",
    "    def evaluate_mrr(self, article_id, word_vector):\n",
    "        reciprocal_ranks = []\n",
    "\n",
    "        for question_data in self.test_questions:\n",
    "            query = question_data['query']\n",
    "            true_answer = question_data['answer']\n",
    "\n",
    "            # Get the best sentence from the text matching utility\n",
    "            best_sentence = self.text_matching_utility.get_best_sentence(query, article_id, word_vector)\n",
    "\n",
    "            # If no answer found, skip this question\n",
    "            if not best_sentence:\n",
    "                continue\n",
    "\n",
    "            # Check if the true answer is in the best sentence\n",
    "            if true_answer in best_sentence:\n",
    "                rank = best_sentence.index(true_answer) + 1  # Rank of the true answer\n",
    "                reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "        # Calculate MRR\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "        return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5beb52f1-45c9-44cf-8431-c629794a8ad8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5beb52f1-45c9-44cf-8431-c629794a8ad8",
    "outputId": "82bcb52e-5995-4b34-9d1e-8a9b20e4022f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID  17574\n",
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: A special prosecutor investigating the corruption scandal that led to President Park  ?s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect.\n",
      "Score 0.36449756195127636 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is the de facto head of Samsung being questioned for bribery?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.40674978209780877 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What scandal led to President Park's impeachment?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.46819122789633294 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of Samsung's vice chairman?\n",
      "Answer: A special prosecutor investigating the corruption scandal that led to President Park  ?s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect.\n",
      "Score 0.36449756195127636 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor investigating the corruption scandal?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.43810532891506093 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is on trial at the Constitutional Court?\n",
      "Answer: Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly?s vote to impeach Ms. Choi last month.\n",
      "Score 0.49466520075934983 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor's office spokesman?\n",
      "Answer: ?\n",
      "Score 0.4005923802428597 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What charges were filed against Ms. Choi by state prosecutors?\n",
      "No answer found\n",
      "Article ID  17574\n",
      "Question: What organization's support was crucial for the merger of two Samsung affiliates?\n",
      "Answer: The emails contained information about the financial support provided by Samsung, the prosecutor?s office said.\n",
      "Score 0.43161217785872114 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "Answer: Samsung gave the largest donations to Ms. Choi?s foundations, totaling $17 million.\n",
      "Score 0.46543391489665975 \n",
      "\n",
      "Mean Reciprocal Rank (MRR) with tf-idf word vector: 0\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TextMatchingUtility\n",
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Create an instance of TestUtility\n",
    "test_utility = TestUtility(tm_utility, test_questions)\n",
    "\n",
    "# Test with tf-idf word vector and article id\n",
    "article_id = 17574  # Replace with appropriate article ID\n",
    "mrr = test_utility.evaluate_mrr(article_id, word_vector='tf-idf')\n",
    "print(\"Mean Reciprocal Rank (MRR) with tf-idf word vector:\", mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58aafc9f-6c3e-4a0b-9353-7a7571b58098",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58aafc9f-6c3e-4a0b-9353-7a7571b58098",
    "outputId": "60c02480-cbb5-4fff-a556-277ad3ef3d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article ID  17574\n",
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: Mr. Lee effectively runs Samsung, South Korea?s largest conglomerate Mr. Lee is the son of Korea?s chairman, Lee   who has been incapacitated with health problems.\n",
      "Score 0.8360479012668263 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is the de facto head of Samsung being questioned for bribery?\n",
      "Answer: Mr. Lee effectively runs Samsung, South Korea?s largest conglomerate Mr. Lee is the son of Korea?s chairman, Lee   who has been incapacitated with health problems.\n",
      "Score 0.8393142433865164 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What scandal led to President Park's impeachment?\n",
      "Answer: SEOUL, South Korea  ?\n",
      "Score 0.8743210249797997 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of Samsung's vice chairman?\n",
      "Answer: The reference on Wednesday to possible perjury charges against Mr. Lee stemmed from that testimony.\n",
      "Score 0.833159548273236 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor investigating the corruption scandal?\n",
      "Answer: In November, state prosecutors indicted Ms. Choi on charges of coercing 53 big businesses, including Samsung, to contribute $69 million to Ms. Choi two foundations.\n",
      "Score 0.8390553654061038 \n",
      "\n",
      "Article ID  17574\n",
      "Question: Who is on trial at the Constitutional Court?\n",
      "Answer: Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly?s vote to impeach Ms. Choi last month.\n",
      "Score 0.8783885162269502 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What is the name of the special prosecutor's office spokesman?\n",
      "Answer: The reference on Wednesday to possible perjury charges against Mr. Lee stemmed from that testimony.\n",
      "Score 0.8760930664635133 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What charges were filed against Ms. Choi by state prosecutors?\n",
      "Answer: ?\n",
      "Score 0.852307642530573 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What organization's support was crucial for the merger of two Samsung affiliates?\n",
      "Answer: 3 million to a winter sports program for young athletes that Ms. Choi and her nephew ran.\n",
      "Score 0.8786408877971373 \n",
      "\n",
      "Article ID  17574\n",
      "Question: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "Answer: The special prosecutor, which took over the investigations from the state prosecutors last month, has been looking into possible bribery charges against not only Ms. Park but the businesses, particularly Samsung.\n",
      "Score 0.8462862889807701 \n",
      "\n",
      "Mean Reciprocal Rank (MRR) with spaCy word vector: 0\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of TextMatchingUtility\n",
    "tm_utility = TextMatchingUtility(news_dataset)\n",
    "\n",
    "# Create an instance of TestUtility\n",
    "test_utility = TestUtility(tm_utility, test_questions)\n",
    "\n",
    "# Test with spaCy word vector and article id\n",
    "article_id = 17574  # Replace with appropriate article ID\n",
    "mrr = test_utility.evaluate_mrr(article_id, word_vector='spaCy')\n",
    "print(\"Mean Reciprocal Rank (MRR) with spaCy word vector:\", mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c730cb-d95a-41a8-a5bb-f68bc1e1e432",
   "metadata": {
    "id": "33c730cb-d95a-41a8-a5bb-f68bc1e1e432"
   },
   "outputs": [],
   "source": [
    "# Hugging Face. (2018).\n",
    "class QuestionAnsweringSystem:\n",
    "    def __init__(self, model_name='deepset/bert-base-cased-squad2'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "    def answer_question(self, question, article_id):\n",
    "        passage = news_dataset.loc[news_dataset['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        inputs = self.tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation=True, truncation_strategy='longest_first')\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        start_index = torch.argmax(start_logits)\n",
    "        end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "        input_tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "        for i, token in enumerate(answer_tokens):\n",
    "            if token == self.tokenizer.cls_token_id:\n",
    "                start_index += 1\n",
    "            elif token == self.tokenizer.sep_token_id:\n",
    "                end_index -= 1\n",
    "        answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "        answer = self.tokenizer.decode(answer_tokens)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cd8918a-0e4d-4477-a33a-b4ca9dd6bfb4",
   "metadata": {
    "id": "8cd8918a-0e4d-4477-a33a-b4ca9dd6bfb4"
   },
   "outputs": [],
   "source": [
    "#coding from lecture\n",
    "class TestUtility:\n",
    "    def __init__(self, test_questions):\n",
    "        self.test_questions = test_questions\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(test_questions, predicted_labels):\n",
    "        if len(test_questions) != len(predicted_labels):\n",
    "            raise ValueError(\"Length of test_questions and predicted_labels must be the same.\")\n",
    "\n",
    "        correct = 0\n",
    "        total = len(test_questions)\n",
    "        for i in range(total):\n",
    "            correct_answer = test_questions[i]['answer'].lower()\n",
    "            predicted_label = predicted_labels[i].lower()\n",
    "            correct_answer = correct_answer.replace(\" \", \"\")\n",
    "            print(correct_answer,predicted_label)\n",
    "            if correct_answer in predicted_label:\n",
    "                correct += 1\n",
    "        if total == 0:\n",
    "            return 0  # Return 0 if there are no test questions\n",
    "        return correct / total\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_reciprocal_rank(test_questions, predicted_labels):\n",
    "        rr_sum = 0\n",
    "        total = len(test_questions)\n",
    "        for i in range(total):\n",
    "            correct_answer = test_questions[i]['answer'].lower()\n",
    "            predicted_labels_lower = predicted_labels[i].lower()\n",
    "            correct_answer = correct_answer.replace(\" \", \"\")\n",
    "            if correct_answer in predicted_labels_lower:\n",
    "                rr_sum += 1 / (predicted_labels_lower.index(correct_answer) + 1)\n",
    "        return rr_sum / total if total != 0 else 0\n",
    "\n",
    "    def evaluate_performance(self, predicted_labels):\n",
    "        acc = self.accuracy(self.test_questions, predicted_labels)\n",
    "        mrr = self.mean_reciprocal_rank(self.test_questions, predicted_labels)\n",
    "\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Mean Reciprocal Rank:\", mrr)\n",
    "\n",
    "    def get_predicted_labels(self, article_id, qa_model):\n",
    "        start_time = time.time()\n",
    "        answers = []\n",
    "        print_query = []\n",
    "        for index, question in enumerate(self.test_questions):\n",
    "            query = qa_model.answer_question(question['query'], article_id)\n",
    "            predicted_labels = query.replace(\" \", \"\")\n",
    "            answers.append(predicted_labels)\n",
    "            print_query.append(query)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(\"Execution time:\", execution_time, \"seconds\")\n",
    "        return answers\n",
    "\n",
    "\n",
    "\n",
    "    def get_predicted_labels_all(self, qa_model):\n",
    "        start_time = time.time()\n",
    "        answers = []\n",
    "        print_query = []\n",
    "        for index, question in enumerate(self.test_questions):\n",
    "            query = qa_model.answer_question(question['query'], question['passage_id'])\n",
    "            predicted_labels = query.replace(\" \", \"\")\n",
    "            answers.append(predicted_labels)\n",
    "            print_query.append(query)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(\"Execution time:\", execution_time, \"seconds\")\n",
    "        return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71f27a62-f22e-4154-bfbb-3234aa462caf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f27a62-f22e-4154-bfbb-3234aa462caf",
    "outputId": "602bcf0f-1043-497a-bbf8-71d2152f32a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: Jay Y. Lee\n"
     ]
    }
   ],
   "source": [
    "article_id = 17574\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "\n",
    "qa_system = QuestionAnsweringSystem()\n",
    "answer = qa_system.answer_question(question, article_id)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "341fcb0b-bca3-4074-9ac4-848cbedc72fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "341fcb0b-bca3-4074-9ac4-848cbedc72fb",
    "outputId": "77e7f215-4349-4ed6-ade3-80c59ef5085e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
       " {'query': 'Who is the de facto head of Samsung being questioned for bribery?',\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': \"What scandal led to President Park's impeachment?\",\n",
       "  'answer': 'corruption scandal'},\n",
       " {'query': \"What is the name of Samsung's vice chairman?\",\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': 'What is the name of the special prosecutor investigating the corruption scandal?',\n",
       "  'answer': '[SEP]'},\n",
       " {'query': 'Who is on trial at the Constitutional Court?',\n",
       "  'answer': 'Ms. Park'},\n",
       " {'query': \"What is the name of the special prosecutor's office spokesman?\",\n",
       "  'answer': 'Lee'},\n",
       " {'query': 'What charges were filed against Ms. Choi by state prosecutors?',\n",
       "  'answer': 'coercing 53 big businesses'},\n",
       " {'query': \"What organization's support was crucial for the merger of two Samsung affiliates?\",\n",
       "  'answer': 'National Pension Service'},\n",
       " {'query': \"What amount did Samsung contribute to Ms. Choi's winter sports program?\",\n",
       "  'answer': '$1.3 million'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "700bbc91-f8ad-4dc0-9b9d-0594d05689bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "700bbc91-f8ad-4dc0-9b9d-0594d05689bb",
    "outputId": "e8ecedb2-0c37-4edf-8e74-6b7fdf65adc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 23.87866711616516 seconds\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations.alsosaiddonationvoluntary,suggestingcompanyvictimextortion,participantbribery.referencewednesdaypossibleperjurychargemr.leestemmedtestimony.specialprosecutor'sofficesaidevidencemr.leereceivedrequestbriberypresidentorderedsamsungsubsidiarysendbribedestinationdesignatedpresident.askednationalassemblyfileperjurycomplaintmr.lee,wouldauthorizespecialprosecutoropeninvestigationcharge.askedwhetherinvestigatorwouldseekarrestmr.leebriberycharges,spokesmanspecialprosecutor'soffice,leesaid,possibilityopen.november,stateprosecutorindictedms.choichargecoercing53bigbusinesses,includingsamsung,contribute$69milliontwofoundations\n",
      "jayy.lee jayy.lee\n",
      "[sep] jayy.lee\n",
      "ms.park jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations\n",
      "lee jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations\n",
      "coercing53bigbusinesses twofoundations\n",
      "nationalpensionservice jayy.lee,vicechairmansamsung,questionedthursday,accordingspecialprosecutor'soffice,recommendedalsoinvestigatedsuspicionperjury.mr.leeeffectivelyrunsamsung,southkorea'slargestconglomeratesonchairman,leeincapacitatedhealthproblems.expectedaskedwhetherdonationsamsungmadetwofoundationcontrolledchoilongtimefriendpresident,amountedbribes,role,any,playeddecisiongivemoney.investigatorsspecialprosecutor'sofficequestionedseniorsamsungexecutivesuspectbriberyaccusations.neithersamsungmr.leerespondedimmediatelyannouncementwednesday.allegationsms.parkhelpedms.choiextortmillionbribesamsungcompanyheartcorruptionscandallednationalassembly'svoteimpeachlastmonth.sincethen,ms.park'spowersuspended,trialconstitutionalcourt,ultimatelydecidewhetherendpresidency.lastmonth,mr.leetestifiednationalassemblyhearinginvolveddecisionsamsungmakedonations.alsosaiddonationvoluntary,suggestingcompanyvictimextortion,participantbribery.referencewednesdaypossibleperjurychargemr.leestemmedtestimony.specialprosecutor'sofficesaidevidencemr.leereceivedrequestbriberypresidentorderedsamsungsubsidiarysendbribedestinationdesignatedpresident.askednationalassemblyfileperjurycomplaintmr.lee,wouldauthorizespecialprosecutoropeninvestigationcharge.askedwhetherinvestigatorwouldseekarrestmr.leebriberycharges,spokesmanspecialprosecutor'soffice,leesaid,possibilityopen.november,stateprosecutorindictedms.choichargecoercing53bigbusinesses,includingsamsung,contribute$69milliontwofoundations\n",
      "$1.3million $69million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.3170212365743092\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system)\n",
    "\n",
    "# Now you can pass these predicted labels to evaluate_performance method to evaluate performance\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75770c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.1:17904\n",
      "\n",
      "Question 1: What movie is seen as a leading contender for Best Picture at the 89th Academy Awards?\n",
      "\n",
      "Predicted Answer 1: Vin Diesel\n",
      "\n",
      "Actual Answer 1: Moonlight\n",
      "\n",
      "Article no.2:18166\n",
      "\n",
      "Question 2: Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?\n",
      "\n",
      "Predicted Answer 2: Mitch McConnell, Wednesday invoke nuclear option abandon threshold confirmation. end gridlock, would say, can, Mitch, go nuclear,? president said. Democrats weighing strategy opposing nomination Judge Neil M. Gorsuch debating aggressively pursue battle seat many believe stolen party. selecting respected, deeply conservative jurist, Mr. Trump dared Democrats pursue kind blanket obstructionism long accused Republicans embracing Obama administration. would absolute shame man quality put neglect, said Roosevelt Room White House. Democrats, struggled match fury zeal party's base wave activism since election, showdown may prove unavoidable, doubling referendum resistance tactic White House liberal fear. Democrats intend repeatedly remind public Republicans? treatment Merrick B. Garland, President Barack Obama's nominee fill vacant seat last year, blocked even receiving hearing. Mr. McConnell said justice seated election year, even though prohibition action. Now, gambit successful, Republicans seek capitalize groundwork laid since Mr. Trump's election. Leading conservative group united campaign help Judge Gorsuch, producing television commercials, planning gathering megachurches contacting supporter encourage demand vote senators. Republicans leery Mr. Trump's campaign last year, prospect adding conservative court often powerful motivator stay line. rewarded faith. Wednesday, Judge Gorsuch made initial courtesy visit senator Capitol Hill\n",
      "\n",
      "Actual Answer 2: Mitch McConnell\n",
      "\n",
      "Article no.3:18166\n",
      "\n",
      "Question 3: What tactic did President Trump suggest Senate Majority Leader Mitch McConnell use to confirm Neil Gorsuch to the Supreme Court?\n",
      "\n",
      "Predicted Answer 3: invoke nuclear option abandon threshold confirmation. end gridlock, would say, can, Mitch, go nuclear,? president said. Democrats weighing strategy opposing nomination Judge Neil M. Gorsuch debating aggressively pursue battle seat many believe stolen party. selecting respected, deeply conservative jurist, Mr. Trump dared Democrats pursue kind blanket obstructionism long accused Republicans embracing Obama administration. would absolute shame man quality put neglect, said Roosevelt Room White House. Democrats, struggled match fury zeal party's base wave activism since election, showdown may prove unavoidable, doubling referendum resistance tactic White House liberal fear. Democrats intend repeatedly remind public Republicans? treatment Merrick B. Garland, President Barack Obama's nominee fill vacant seat last year, blocked even receiving hearing\n",
      "\n",
      "Actual Answer 3: Nuclear option\n",
      "\n",
      "Article no.4:18055\n",
      "\n",
      "Question 4: What is the name of Talea's mother?\n",
      "\n",
      "Predicted Answer 4: \n",
      "\n",
      "Actual Answer 4: Trenicia\n",
      "\n",
      "Article no.5:17776\n",
      "\n",
      "Question 5: Who is the Roman Catholic Archbishop of New York?\n",
      "\n",
      "Predicted Answer 5: \n",
      "\n",
      "Actual Answer 5: Cardinal Dolan\n",
      "\n",
      "Article no.6:17776\n",
      "\n",
      "Question 6: How many religious leaders are scheduled to participate in Donald J. Trump's inauguration ceremony?\n",
      "\n",
      "Predicted Answer 6: Six\n",
      "\n",
      "Actual Answer 6: Six\n",
      "\n",
      "Article no.7:18079\n",
      "\n",
      "Question 7: What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?\n",
      "\n",
      "Predicted Answer 7: brittle bones, cancer birth defect children\n",
      "\n",
      "Actual Answer 7: Enewetak Atoll\n",
      "\n",
      "Article no.8:17895\n",
      "\n",
      "Question 8: What is the biggest problem identified by Energy Department reports regarding the cleanup of Enewetak Atoll?\n",
      "\n",
      "Predicted Answer 8: cast ballot poll present photo identification, like Texas driver's gun license, military ID passport. Federal court repeatedly ruled law racially discriminatory. Texas law first blocked Section 5 federal Voting Rights Act, required state locality history discrimination obtain federal permission changing voting procedures. Supreme Court effectively struck Section 5 2013 Shelby County v. Holder, Alabama case, Texas official announced would start enforcing ID law. trial 2014, Judge Nelva Gonzales Ramos Federal District Court Corpus Christi struck law Oct. 9 opinion. said adopted unconstitutional discriminatory purpose? effect disenfranchise disproportionate number Hispanics. 2015, panel United States Court Appeals Fifth Circuit, New Orleans, vacated part ruling concerning law's purpose affirmed part concerning effect. Last July, full Fifth Circuit largely adopted panel's distinction reasoning, returned case trial court consider appropriate remedy. Texas official nonetheless asked Supreme Court review appeal court's ruling immediately. people group challenging law, official said, presented evidence law resulted diminished minority political participation prevented even single person voting\n",
      "\n",
      "Actual Answer 8: Runit Island\n",
      "\n",
      "Article no.9:18253\n",
      "\n",
      "Question 9: According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?\n",
      "\n",
      "Predicted Answer 9: SET MOOD BEFOREHAND Use journey destination opportunity get vacation mode : flying, use pair headphone order glass\n",
      "\n",
      "Actual Answer 9: Choose smaller cities\n",
      "\n",
      "Article no.10:17574\n",
      "\n",
      "Question 10: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "\n",
      "Predicted Answer 10: $ 69 million\n",
      "\n",
      "Actual Answer 10: $1.3 million\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(test_questions_all):\n",
    "    answer = qa_system.answer_question(question['query'], question['passage_id'])\n",
    "    # Print the question, passage, and answer\n",
    "    print(\"Article no.{}:{}\\n\".format(i+1, question['passage_id']))\n",
    "    print(\"Question {}: {}\\n\".format(i+1, question['query']))\n",
    "    print(\"Predicted Answer {}: {}\\n\".format(i+1, answer))\n",
    "    print(\"Actual Answer {}: {}\\n\".format(i+1, question['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60eff9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 22.984974145889282 seconds\n",
      "moonlight vindiesel\n",
      "mitchmcconnell mitchmcconnell,wednesdayinvokenuclearoptionabandonthresholdconfirmation.endgridlock,wouldsay,can,mitch,gonuclear,?presidentsaid.democratsweighingstrategyopposingnominationjudgeneilm.gorsuchdebatingaggressivelypursuebattleseatmanybelievestolenparty.selectingrespected,deeplyconservativejurist,mr.trumpdareddemocratspursuekindblanketobstructionismlongaccusedrepublicansembracingobamaadministration.wouldabsoluteshamemanqualityputneglect,saidrooseveltroomwhitehouse.democrats,struggledmatchfuryzealparty'sbasewaveactivismsinceelection,showdownmayproveunavoidable,doublingreferendumresistancetacticwhitehouseliberalfear.democratsintendrepeatedlyremindpublicrepublicans?treatmentmerrickb.garland,presidentbarackobama'snomineefillvacantseatlastyear,blockedevenreceivinghearing.mr.mcconnellsaidjusticeseatedelectionyear,eventhoughprohibitionaction.now,gambitsuccessful,republicansseekcapitalizegroundworklaidsincemr.trump'selection.leadingconservativegroupunitedcampaignhelpjudgegorsuch,producingtelevisioncommercials,planninggatheringmegachurchescontactingsupporterencouragedemandvotesenators.republicansleerymr.trump'scampaignlastyear,prospectaddingconservativecourtoftenpowerfulmotivatorstayline.rewardedfaith.wednesday,judgegorsuchmadeinitialcourtesyvisitsenatorcapitolhill\n",
      "nuclearoption invokenuclearoptionabandonthresholdconfirmation.endgridlock,wouldsay,can,mitch,gonuclear,?presidentsaid.democratsweighingstrategyopposingnominationjudgeneilm.gorsuchdebatingaggressivelypursuebattleseatmanybelievestolenparty.selectingrespected,deeplyconservativejurist,mr.trumpdareddemocratspursuekindblanketobstructionismlongaccusedrepublicansembracingobamaadministration.wouldabsoluteshamemanqualityputneglect,saidrooseveltroomwhitehouse.democrats,struggledmatchfuryzealparty'sbasewaveactivismsinceelection,showdownmayproveunavoidable,doublingreferendumresistancetacticwhitehouseliberalfear.democratsintendrepeatedlyremindpublicrepublicans?treatmentmerrickb.garland,presidentbarackobama'snomineefillvacantseatlastyear,blockedevenreceivinghearing\n",
      "trenicia \n",
      "cardinaldolan \n",
      "six six\n",
      "enewetakatoll brittlebones,cancerbirthdefectchildren\n",
      "runitisland castballotpollpresentphotoidentification,liketexasdriver'sgunlicense,militaryidpassport.federalcourtrepeatedlyruledlawraciallydiscriminatory.texaslawfirstblockedsection5federalvotingrightsact,requiredstatelocalityhistorydiscriminationobtainfederalpermissionchangingvotingprocedures.supremecourteffectivelystrucksection52013shelbycountyv.holder,alabamacase,texasofficialannouncedwouldstartenforcingidlaw.trial2014,judgenelvagonzalesramosfederaldistrictcourtcorpuschrististrucklawoct.9opinion.saidadoptedunconstitutionaldiscriminatorypurpose?effectdisenfranchisedisproportionatenumberhispanics.2015,panelunitedstatescourtappealsfifthcircuit,neworleans,vacatedpartrulingconcerninglaw'spurposeaffirmedpartconcerningeffect.lastjuly,fullfifthcircuitlargelyadoptedpanel'sdistinctionreasoning,returnedcasetrialcourtconsiderappropriateremedy.texasofficialnonethelessaskedsupremecourtreviewappealcourt'srulingimmediately.peoplegroupchallenginglaw,officialsaid,presentedevidencelawresulteddiminishedminoritypoliticalparticipationpreventedevensinglepersonvoting\n",
      "choosesmallercities setmoodbeforehandusejourneydestinationopportunitygetvacationmode:flying,usepairheadphoneorderglass\n",
      "$1.3million $69million\n",
      "Accuracy: 0.3\n",
      "Mean Reciprocal Rank: 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions_all)\n",
    "predicted_labels = test_utility.get_predicted_labels_all(qa_system)\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee88b72-d7cc-43fc-a614-935f53138d5c",
   "metadata": {
    "id": "aee88b72-d7cc-43fc-a614-935f53138d5c"
   },
   "outputs": [],
   "source": [
    "### ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b1bd36-6320-49b9-bad1-64e28679399a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73b1bd36-6320-49b9-bad1-64e28679399a",
    "outputId": "d4158717-964f-4483-bff9-eb16b87ad177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer:  Jay Y. Lee\n"
     ]
    }
   ],
   "source": [
    "article_id = 17574\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "\n",
    "qa_system_roberta = QuestionAnsweringSystem(model_name= \"deepset/roberta-base-squad2\")\n",
    "answer = qa_system_roberta.answer_question(question, article_id)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0a31a0b-e968-4e60-ba0e-d1eecd51e22c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0a31a0b-e968-4e60-ba0e-d1eecd51e22c",
    "outputId": "ec7f98d3-b703-4768-a032-47ba4c763df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jay Y. Lee', 'Jay Y. Lee', 'corruption scandal', 'Jay Y. Lee', '[SEP]', 'Ms. Park', 'Lee', 'coercing 53 big businesses', 'National Pension Service', '$1.3 million']\n"
     ]
    }
   ],
   "source": [
    "true_labels = [item['answer'] for item in test_questions]\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eeef873-90ae-4a73-a23f-c9f6edd8e838",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eeef873-90ae-4a73-a23f-c9f6edd8e838",
    "outputId": "d56e019c-2632-46ae-ace3-0c1f4340df27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 23.691344022750854 seconds\n",
      "['Jay Y. Lee', 'Jay Y. Lee', 'corruption scandal', 'Jay Y. Lee', '[SEP]', 'Ms. Park', 'Lee', 'coercing 53 big businesses', 'National Pension Service', '$1.3 million']\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal corruption\n",
      "jayy.lee jayy.lee\n",
      "[sep] \n",
      "ms.park \n",
      "lee \n",
      "coercing53bigbusinesses coercing53bigbusinesses\n",
      "nationalpensionservice nationalpensionservice\n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.6\n",
      "Execution time: 23.71089196205139 seconds\n",
      "['Jay Y. Lee', 'Jay Y. Lee', 'corruption scandal', 'Jay Y. Lee', '[SEP]', 'Ms. Park', 'Lee', 'coercing 53 big businesses', 'National Pension Service', '$1.3 million']\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal corruption\n",
      "jayy.lee jayy.lee\n",
      "[sep] \n",
      "ms.park \n",
      "lee \n",
      "coercing53bigbusinesses coercing53bigbusinesses\n",
      "nationalpensionservice nationalpensionservice\n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system_roberta)\n",
    "\n",
    "print(true_labels)\n",
    "test_utility.evaluate_performance(predicted_labels)# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_system_roberta)\n",
    "\n",
    "print(true_labels)\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "005950aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.1:17904\n",
      "\n",
      "Question 1: What movie is seen as a leading contender for Best Picture at the 89th Academy Awards?\n",
      "\n",
      "Predicted Answer 1:  Moonlight\n",
      "\n",
      "Actual Answer 1: Moonlight\n",
      "\n",
      "Article no.2:18166\n",
      "\n",
      "Question 2: Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?\n",
      "\n",
      "Predicted Answer 2:  Mitch McConnell\n",
      "\n",
      "Actual Answer 2: Mitch McConnell\n",
      "\n",
      "Article no.3:18166\n",
      "\n",
      "Question 3: What tactic did President Trump suggest Senate Majority Leader Mitch McConnell use to confirm Neil Gorsuch to the Supreme Court?\n",
      "\n",
      "Predicted Answer 3:  nuclear option\n",
      "\n",
      "Actual Answer 3: Nuclear option\n",
      "\n",
      "Article no.4:18055\n",
      "\n",
      "Question 4: What is the name of Talea's mother?\n",
      "\n",
      "Predicted Answer 4:  Trenicia Childs\n",
      "\n",
      "Actual Answer 4: Trenicia\n",
      "\n",
      "Article no.5:17776\n",
      "\n",
      "Question 5: Who is the Roman Catholic Archbishop of New York?\n",
      "\n",
      "Predicted Answer 5:  Cardinal Dolan\n",
      "\n",
      "Actual Answer 5: Cardinal Dolan\n",
      "\n",
      "Article no.6:17776\n",
      "\n",
      "Question 6: How many religious leaders are scheduled to participate in Donald J. Trump's inauguration ceremony?\n",
      "\n",
      "Predicted Answer 6:  Six\n",
      "\n",
      "Actual Answer 6: Six\n",
      "\n",
      "Article no.7:18079\n",
      "\n",
      "Question 7: What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?\n",
      "\n",
      "Predicted Answer 7:  Enewetak Atoll\n",
      "\n",
      "Actual Answer 7: Enewetak Atoll\n",
      "\n",
      "Article no.8:17895\n",
      "\n",
      "Question 8: What is the biggest problem identified by Energy Department reports regarding the cleanup of Enewetak Atoll?\n",
      "\n",
      "Predicted Answer 8: \n",
      "\n",
      "Actual Answer 8: Runit Island\n",
      "\n",
      "Article no.9:18253\n",
      "\n",
      "Question 9: According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?\n",
      "\n",
      "Predicted Answer 9: \n",
      "\n",
      "Actual Answer 9: Choose smaller cities\n",
      "\n",
      "Article no.10:17574\n",
      "\n",
      "Question 10: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "\n",
      "Predicted Answer 10:  $1. 3 million\n",
      "\n",
      "Actual Answer 10: $1.3 million\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(test_questions_all):\n",
    "    answer = qa_system_roberta.answer_question(question['query'], question['passage_id'])\n",
    "    # Print the question, passage, and answer\n",
    "    print(\"Article no.{}:{}\\n\".format(i+1, question['passage_id']))\n",
    "    print(\"Question {}: {}\\n\".format(i+1, question['query']))\n",
    "    print(\"Predicted Answer {}: {}\\n\".format(i+1, answer))\n",
    "    print(\"Actual Answer {}: {}\\n\".format(i+1, question['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f913c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 22.624534130096436 seconds\n",
      "moonlight moonlight\n",
      "mitchmcconnell mitchmcconnell\n",
      "nuclearoption nuclearoption\n",
      "trenicia treniciachilds\n",
      "cardinaldolan cardinaldolan\n",
      "six six\n",
      "enewetakatoll enewetakatoll\n",
      "runitisland \n",
      "choosesmallercities \n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.8\n",
      "Mean Reciprocal Rank: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions_all)\n",
    "predicted_labels = test_utility.get_predicted_labels_all(qa_system_roberta)\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37c901fa-2ac1-457f-b5f0-9215604fb3ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37c901fa-2ac1-457f-b5f0-9215604fb3ed",
    "outputId": "54066459-77ab-42a4-de23-980717c5a2fd"
   },
   "outputs": [],
   "source": [
    "# Hugging Face. (2018).\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', resume_download=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', resume_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6c557d3-3758-407e-8d81-3c5d1c67de70",
   "metadata": {
    "id": "d6c557d3-3758-407e-8d81-3c5d1c67de70"
   },
   "outputs": [],
   "source": [
    "#Code reused from Practical Lab\n",
    "import heapq\n",
    "\n",
    "class QuestionAnsweringModel:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def tokenize(self, question, answer_text):\n",
    "        '''\n",
    "        Tokenizes the input question and answer_text and sets the segment IDs.\n",
    "        '''\n",
    "        # Apply the tokenizer to the encode text, treating them as a question, answer_text pair.\n",
    "        input_ids = self.tokenizer.encode(question, answer_text, max_length=512, truncation=True, truncation_strategy='only_second')\n",
    "\n",
    "        # Report how long the input sequence is.\n",
    "        # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "        # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "        sep_index = input_ids.index(self.tokenizer.sep_token_id)\n",
    "\n",
    "        # The number of segment A tokens includes the [SEP] token itself.\n",
    "        num_seg_a = sep_index + 1\n",
    "\n",
    "        # The remainder are segment B.\n",
    "        num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "        # Construct the list of 0s and 1s.\n",
    "        segment_ids = [0] * num_seg_a + [1] * num_seg_b\n",
    "\n",
    "        # There should be a segment_id for every input token.\n",
    "        assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "        return input_ids, segment_ids\n",
    "\n",
    "    def evaluate(self, input_ids, segment_ids):\n",
    "        '''\n",
    "        Evaluates the input question and answer_text using the model.\n",
    "        '''\n",
    "        # Run the question through the model.\n",
    "        model_scores = self.model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "        start_scores = model_scores.start_logits\n",
    "        end_scores = model_scores.end_logits\n",
    "\n",
    "        return start_scores, end_scores\n",
    "\n",
    "    def reconstruct_answer(self, input_ids, start_scores, end_scores):\n",
    "        '''\n",
    "        Reconstructs the answer from the model's output.\n",
    "        '''\n",
    "        # Find the tokens with the highest `start` and `end` scores.\n",
    "        answer_start = torch.argmax(start_scores)\n",
    "        answer_end = torch.argmax(end_scores)\n",
    "\n",
    "        # Get the string versions of the input tokens.\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        # Start with the first token.\n",
    "        answer = tokens[answer_start]\n",
    "\n",
    "        # Select the remaining answer tokens and join them with whitespace.\n",
    "        for i in range(answer_start + 1, answer_end + 1):\n",
    "            # If it's a subword token, then recombine it with the previous token.\n",
    "            if tokens[i][0:2] == '##':\n",
    "                answer += tokens[i][2:]\n",
    "            # Otherwise, add a space then the token.\n",
    "            else:\n",
    "                answer += ' ' + tokens[i]\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def answer_question(self, question, article_id):\n",
    "        '''\n",
    "        Takes a `question` string and an `answer_text` string (which contains the\n",
    "        answer), and identifies the words within the `answer_text` that are the\n",
    "        answer. Prints them out.\n",
    "        '''\n",
    "        answer_text = news_dataset.loc[news_dataset['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        input_ids, segment_ids = self.tokenize(question, answer_text)\n",
    "        start_scores, end_scores = self.evaluate(input_ids, segment_ids)\n",
    "        answer = self.reconstruct_answer(input_ids, start_scores, end_scores)\n",
    "        return answer\n",
    "\n",
    "    def answer_question_top3(self, question, article_id):\n",
    "        answer_text = news_dataset.loc[news_dataset['id'] == article_id, 'processed_article'].iloc[0]\n",
    "        input_ids, segment_ids = self.tokenize(question, answer_text)\n",
    "        start_scores, end_scores = self.evaluate(input_ids, segment_ids)\n",
    "        answers = []\n",
    "        max_answers = 3\n",
    "        # Find the top answer candidates\n",
    "        for _ in range(max_answers):\n",
    "            answer_start = torch.argmax(start_scores)\n",
    "            answer_end = torch.argmax(end_scores)\n",
    "            # Get the string versions of the input tokens.\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "            answer = tokens[answer_start]\n",
    "            for i in range(answer_start + 1, answer_end + 1):\n",
    "                if tokens[i][0:2] == '##':\n",
    "                    answer += tokens[i][2:]\n",
    "                else:\n",
    "                    answer += ' ' + tokens[i]\n",
    "            confidence_score = start_scores[0][answer_start] + end_scores[0][answer_end]\n",
    "            answers.append((answer, confidence_score.item()))\n",
    "            # Mask the used tokens\n",
    "            start_scores[0][answer_start] = end_scores[0][answer_end] = float('-inf')\n",
    "        # Sort answers by confidence scores\n",
    "        top_answers = heapq.nlargest(max_answers, answers, key=lambda x: x[1])\n",
    "        return [ans[0] for ans in top_answers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "201ef03f-a4e1-4ba7-bb6d-e8a798f1c250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "201ef03f-a4e1-4ba7-bb6d-e8a798f1c250",
    "outputId": "88b81404-4e7e-4b2c-88fc-ec0a127cf36e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the vice chairman of Samsung?\n",
      "Answer: ['jay y . lee', 'lee ,', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "qa_model = QuestionAnsweringModel(model, tokenizer)\n",
    "\n",
    "# Define your question and article ID\n",
    "question = \"Who is the vice chairman of Samsung?\"\n",
    "article_id =17574\n",
    "\n",
    "# Call the answer_question method to get the answer\n",
    "answer = qa_model.answer_question_top3(question, article_id)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed93e50b-267d-428a-95f2-cb6203bae6a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed93e50b-267d-428a-95f2-cb6203bae6a0",
    "outputId": "cb440ace-4c99-41f5-fad5-edcf98ffb5e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jayy.lee', 'jayy.lee', 'corruption', 'jayy.lee', '[SEP]', 'ms.park', 'lee', 'coercing53bigbusinesses', \"[CLS]whatorganization'ssupportwascrucialforthemergeroftwosamsungaffiliates?[SEP]\", '$1.3million']\n"
     ]
    }
   ],
   "source": [
    "def predicted_labels(test_questions):\n",
    "    start_time = time.time()\n",
    "    answers = []\n",
    "    article_id = 17574\n",
    "    for index, question in enumerate(test_questions):\n",
    "        query = qa_model.answer_question(question['query'], article_id)\n",
    "        predicted_labels = query.replace(\" \", \"\")\n",
    "        answers.append(predicted_labels)\n",
    "    return answers\n",
    "predicted_labels = predicted_labels(test_questions)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3dfd69a-5569-4eef-b04f-23460682ef74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3dfd69a-5569-4eef-b04f-23460682ef74",
    "outputId": "93830af9-154c-4328-ff34-f3117e6c57b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Who is the vice chairman of Samsung?', 'answer': 'Jay Y. Lee'},\n",
       " {'query': 'Who is the de facto head of Samsung being questioned for bribery?',\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': \"What scandal led to President Park's impeachment?\",\n",
       "  'answer': 'corruption scandal'},\n",
       " {'query': \"What is the name of Samsung's vice chairman?\",\n",
       "  'answer': 'Jay Y. Lee'},\n",
       " {'query': 'What is the name of the special prosecutor investigating the corruption scandal?',\n",
       "  'answer': '[SEP]'},\n",
       " {'query': 'Who is on trial at the Constitutional Court?',\n",
       "  'answer': 'Ms. Park'},\n",
       " {'query': \"What is the name of the special prosecutor's office spokesman?\",\n",
       "  'answer': 'Lee'},\n",
       " {'query': 'What charges were filed against Ms. Choi by state prosecutors?',\n",
       "  'answer': 'coercing 53 big businesses'},\n",
       " {'query': \"What organization's support was crucial for the merger of two Samsung affiliates?\",\n",
       "  'answer': 'National Pension Service'},\n",
       " {'query': \"What amount did Samsung contribute to Ms. Choi's winter sports program?\",\n",
       "  'answer': '$1.3 million'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcca66eb-f729-49ff-935b-6aaf463a9d92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcca66eb-f729-49ff-935b-6aaf463a9d92",
    "outputId": "edabd8ec-cbdb-4880-a8a5-214ad96b68b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 83.07251477241516 seconds\n",
      "jayy.lee jayy.lee\n",
      "jayy.lee jayy.lee\n",
      "corruptionscandal corruption\n",
      "jayy.lee jayy.lee\n",
      "[sep] [sep]\n",
      "ms.park ms.park\n",
      "lee lee\n",
      "coercing53bigbusinesses coercing53bigbusinesses\n",
      "nationalpensionservice [cls]whatorganization'ssupportwascrucialforthemergeroftwosamsungaffiliates?[sep]\n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.8\n",
      "Mean Reciprocal Rank: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions)\n",
    "\n",
    "# Call get_predicted_labels method to obtain predicted labels\n",
    "article_id = 17574\n",
    "\n",
    "predicted_labels = test_utility.get_predicted_labels(article_id, qa_model)\n",
    "\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5181aae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5181aae",
    "outputId": "f355a89b-703c-4155-a6a8-7e6de919587e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.1:17904\n",
      "\n",
      "Question 1: What movie is seen as a leading contender for Best Picture at the 89th Academy Awards?\n",
      "\n",
      "Predicted Answer 1: young black man miami\n",
      "\n",
      "Actual Answer 1: Moonlight\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.2:18166\n",
      "\n",
      "Question 2: Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?\n",
      "\n",
      "Predicted Answer 2: mitch mcconnell\n",
      "\n",
      "Actual Answer 2: Mitch McConnell\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.3:18166\n",
      "\n",
      "Question 3: What tactic did President Trump suggest Senate Majority Leader Mitch McConnell use to confirm Neil Gorsuch to the Supreme Court?\n",
      "\n",
      "Predicted Answer 3: nuclear option\n",
      "\n",
      "Actual Answer 3: Nuclear option\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.4:18055\n",
      "\n",
      "Question 4: What is the name of Talea's mother?\n",
      "\n",
      "Predicted Answer 4: trenicia childs\n",
      "\n",
      "Actual Answer 4: Trenicia\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.5:17776\n",
      "\n",
      "Question 5: Who is the Roman Catholic Archbishop of New York?\n",
      "\n",
      "Predicted Answer 5: cardinal dolan\n",
      "\n",
      "Actual Answer 5: Cardinal Dolan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.6:17776\n",
      "\n",
      "Question 6: How many religious leaders are scheduled to participate in Donald J. Trump's inauguration ceremony?\n",
      "\n",
      "Predicted Answer 6: six\n",
      "\n",
      "Actual Answer 6: Six\n",
      "\n",
      "Article no.7:18079\n",
      "\n",
      "Question 7: What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?\n",
      "\n",
      "Predicted Answer 7: enewetak\n",
      "\n",
      "Actual Answer 7: Enewetak Atoll\n",
      "\n",
      "Article no.8:17895\n",
      "\n",
      "Question 8: What is the biggest problem identified by Energy Department reports regarding the cleanup of Enewetak Atoll?\n",
      "\n",
      "Predicted Answer 8: [CLS]\n",
      "\n",
      "Actual Answer 8: Runit Island\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article no.9:18253\n",
      "\n",
      "Question 9: According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?\n",
      "\n",
      "Predicted Answer 9: [CLS] according to bonsor , what can travelers do to avoid feeling overwhelmed in large cities ? [SEP] beach spa vacation typically associated relaxation urban getaway tend go , go , go , always case , according michael bonsor , hotel manager rosewood london . absolutely head city relaxing vacation , said . here , mr . bonsor share tip trip busy city setting : set mood beforehand use journey destination opportunity get vacation mode : flying , use pair headphone order glass champagne another drink enjoy get board . watch movie listen music ipad airline ' s entertainment system . driving , plan hit road rush hour , spend hour sitting traffic playlist hand favorite song carry indulgent snack bar good chocolate . idea , mr . bonsor said , start unwinding vacation starts . pick manageable city large city like new york city , paris tokyo usually lend relaxation\n",
      "\n",
      "Actual Answer 9: Choose smaller cities\n",
      "\n",
      "Article no.10:17574\n",
      "\n",
      "Question 10: What amount did Samsung contribute to Ms. Choi's winter sports program?\n",
      "\n",
      "Predicted Answer 10: $ 1 . 3 million\n",
      "\n",
      "Actual Answer 10: $1.3 million\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, question in enumerate(test_questions_all):\n",
    "    answer = qa_model.answer_question(question['query'], question['passage_id'])\n",
    "    # Print the question, passage, and answer\n",
    "    print(\"Article no.{}:{}\\n\".format(i+1, question['passage_id']))\n",
    "    print(\"Question {}: {}\\n\".format(i+1, question['query']))\n",
    "    print(\"Predicted Answer {}: {}\\n\".format(i+1, answer))\n",
    "    print(\"Actual Answer {}: {}\\n\".format(i+1, question['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0nTP2KDhPeOi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0nTP2KDhPeOi",
    "outputId": "f078126c-bc12-4dcd-e944-72a04ec5e0b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 82.80501508712769 seconds\n",
      "moonlight youngblackmanmiami\n",
      "mitchmcconnell mitchmcconnell\n",
      "nuclearoption nuclearoption\n",
      "trenicia treniciachilds\n",
      "cardinaldolan cardinaldolan\n",
      "six six\n",
      "enewetakatoll enewetak\n",
      "runitisland [cls]\n",
      "choosesmallercities [cls]accordingtobonsor,whatcantravelersdotoavoidfeelingoverwhelmedinlargecities?[sep]beachspavacationtypicallyassociatedrelaxationurbangetawaytendgo,go,go,alwayscase,accordingmichaelbonsor,hotelmanagerrosewoodlondon.absolutelyheadcityrelaxingvacation,said.here,mr.bonsorsharetiptripbusycitysetting:setmoodbeforehandusejourneydestinationopportunitygetvacationmode:flying,usepairheadphoneorderglasschampagneanotherdrinkenjoygetboard.watchmovielistenmusicipadairline'sentertainmentsystem.driving,planhitroadrushhour,spendhoursittingtrafficplaylisthandfavoritesongcarryindulgentsnackbargoodchocolate.idea,mr.bonsorsaid,startunwindingvacationstarts.pickmanageablecitylargecitylikenewyorkcity,paristokyousuallylendrelaxation\n",
      "$1.3million $1.3million\n",
      "Accuracy: 0.6\n",
      "Mean Reciprocal Rank: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TestUtility object with test questions\n",
    "test_utility = TestUtility(test_questions_all)\n",
    "predicted_labels = test_utility.get_predicted_labels_all(qa_model)\n",
    "test_utility.evaluate_performance(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "sxd4KTkfQEUR",
   "metadata": {
    "id": "sxd4KTkfQEUR"
   },
   "outputs": [],
   "source": [
    "def ask_question():\n",
    "    article_id = input(\"Enter the article ID (type 'exit' to quit): \")\n",
    "    if article_id.lower() == 'exit':\n",
    "        print(\"Exiting the program...\")\n",
    "        return\n",
    "    try:\n",
    "        article_id = int(article_id)\n",
    "        if article_id not in news_dataset['id'].tolist():\n",
    "            print(\"Invalid article number.\")\n",
    "            ask_question()\n",
    "            return\n",
    "        question = input(\"Ask your question: \")\n",
    "        answer = qa_model.answer_question(question, article_id)\n",
    "        if answer and \"[CLS]\" not in answer and \"[SEP]\" not in answer:\n",
    "            print(\"Answer:\", answer)\n",
    "        else:\n",
    "            print(\"Answer not found.\")\n",
    "    except ValueError:\n",
    "        print(\"Article ID should be an integer. Please try again.\")\n",
    "    ask_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8efc4969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What movie is seen as a leading contender for Best Picture at the 89th Academy Awards?',\n",
       "  'answer': 'Moonlight',\n",
       "  'passage_id': 17904},\n",
       " {'query': 'Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?',\n",
       "  'answer': 'Mitch McConnell',\n",
       "  'passage_id': 18166},\n",
       " {'query': 'What tactic did President Trump suggest Senate Majority Leader Mitch McConnell use to confirm Neil Gorsuch to the Supreme Court?',\n",
       "  'answer': 'Nuclear option',\n",
       "  'passage_id': 18166},\n",
       " {'query': \"What is the name of Talea's mother?\",\n",
       "  'answer': 'Trenicia',\n",
       "  'passage_id': 18055},\n",
       " {'query': 'Who is the Roman Catholic Archbishop of New York?',\n",
       "  'answer': 'Cardinal Dolan',\n",
       "  'passage_id': 17776},\n",
       " {'query': \"How many religious leaders are scheduled to participate in Donald J. Trump's inauguration ceremony?\",\n",
       "  'answer': 'Six',\n",
       "  'passage_id': 17776},\n",
       " {'query': 'What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?',\n",
       "  'answer': 'Enewetak Atoll',\n",
       "  'passage_id': 18079},\n",
       " {'query': 'What is the biggest problem identified by Energy Department reports regarding the cleanup of Enewetak Atoll?',\n",
       "  'answer': 'Runit Island',\n",
       "  'passage_id': 17895},\n",
       " {'query': 'According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?',\n",
       "  'answer': 'Choose smaller cities',\n",
       "  'passage_id': 18253},\n",
       " {'query': \"What amount did Samsung contribute to Ms. Choi's winter sports program?\",\n",
       "  'answer': '$1.3 million',\n",
       "  'passage_id': 17574}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "gWHELXggRog_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWHELXggRog_",
    "outputId": "c36aef6f-05c2-4099-bcd4-7a0a1bf6c895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the article ID (type 'exit' to quit): 2123\n",
      "Invalid article number.\n",
      "Enter the article ID (type 'exit' to quit): 17574\n",
      "Ask your question: What amount did Samsung contribute to Ms. Choi's winter sports program?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: $ 1 . 3 million\n",
      "Enter the article ID (type 'exit' to quit): 18253\n",
      "Ask your question: According to Bonsor, what can travelers do to avoid feeling overwhelmed in large cities?\n",
      "Answer not found.\n",
      "Enter the article ID (type 'exit' to quit): 17776\n",
      "Ask your question: What is the name of the atoll where Tim Snider and other veterans were tasked with cleaning up nuclear fallout?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer not found.\n",
      "Enter the article ID (type 'exit' to quit): 18055\n",
      "Ask your question: What is the name of Talea's mother?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: trenicia childs\n",
      "Enter the article ID (type 'exit' to quit): 17904\n",
      "Ask your question: Who is President Trump encouraging to invoke the nuclear option regarding the confirmation of his nominee to the Supreme Court?\n",
      "Answer not found.\n",
      "Enter the article ID (type 'exit' to quit): exit\n",
      "Exiting the program...\n"
     ]
    }
   ],
   "source": [
    "ask_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {
    "id": "9d3a91b4"
   },
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f51a0",
   "metadata": {},
   "source": [
    "Hugging Face. (n.d.). roberta-base for QA. Retrieved from huggingface:\n",
    "https://huggingface.co/deepset/roberta-base-squad2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d006af4",
   "metadata": {},
   "source": [
    "Hugging Face. (2018). BERT large model (uncased) whole word masking finetuned on SQuAD. Retrieved\n",
    "\n",
    "from huggingface: https://huggingface.co/google-bert/bert-large-uncased-whole-word-masking-\n",
    "finetuned-squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bc8a8",
   "metadata": {},
   "source": [
    "McCormick, C. (2020, March 10). Question Answering with a Fine-Tuned BERT. Retrieved from\n",
    "mccormickml: https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19781b2",
   "metadata": {},
   "source": [
    "Wu, J. (2023, July 21). Information Retrieval 1: TF-IDF based search engine with python code. Retrieved\n",
    "\n",
    "from AI Mind: https://pub.aimind.so/information-retrieval-1-tf-idf-based-search-engine-with-\n",
    "python-code-54cd085786"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {
    "id": "cf7553c1"
   },
   "source": [
    "## C. Appendix"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
